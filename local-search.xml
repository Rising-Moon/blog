<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>测试</title>
    <link href="/blog/2022/03/03/short/test/"/>
    <url>/blog/2022/03/03/short/test/</url>
    
    <content type="html"><![CDATA[<iframe width="640" height="360" frameborder="0" src="https://www.shadertoy.com/embed/WdGfWw?gui=true&t=10&paused=true&muted=false" allowfullscreen></iframe>]]></content>
    
    
    <categories>
      
      <category>零零散散</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Shader</tag>
      
      <tag>ShaderToy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>记录URP-ShaderLibrary常用库作用</title>
    <link href="/blog/2022/03/03/short/URP-Shader-%E5%B8%B8%E7%94%A8%E5%BA%93/"/>
    <url>/blog/2022/03/03/short/URP-Shader-%E5%B8%B8%E7%94%A8%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="URP中的ShaderLibrary"><a href="#URP中的ShaderLibrary" class="headerlink" title="URP中的ShaderLibrary"></a>URP中的ShaderLibrary</h1><ul><li>使用URP时我们通常不去引用核心库的文件，而是引用URP package中的ShaderLibrary文件夹下的hlsl文件，这里整理并且归纳一下各个文件包含的内容，方便之后翻看和定位。</li></ul><span id="more"></span><h2 id="Core-hlsl"><a href="#Core-hlsl" class="headerlink" title="Core.hlsl"></a>Core.hlsl</h2><ul><li>定义了一些常用的用于可编程阶段间传递的数据结构</li></ul><h3 id="包含了一些常用函数"><a href="#包含了一些常用函数" class="headerlink" title="包含了一些常用函数"></a>包含了一些常用函数</h3><ol><li>VertexPositionInputs GetVertexPositionInputs(float3 positionOS)：将模型空间的点转化到世界、投影、裁剪、NDC空间的坐标</li><li>VertexNormalInputs GetVertexNormalInputs(float3 normalOS)：将法向量转化到世界空间（注意：非切向空间）</li><li>VertexNormalInputs GetVertexNormalInputs(float3 normalOS, float4 tangentOS)：将法向量转化到切向空间，tangentOS的w分量用于控制朝向</li><li>float3 GetCameraPositionWS()：获取相机的世界坐标</li></ol><h2 id="DeclareDepthTexture-hlsl"><a href="#DeclareDepthTexture-hlsl" class="headerlink" title="DeclareDepthTexture.hlsl"></a>DeclareDepthTexture.hlsl</h2><ul><li>定义了采样深度贴图的函数</li><li>包含两个函数:</li></ul><figure class="highlight reasonml"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-built_in">float</span> <span class="hljs-constructor">SampleSceneDepth(<span class="hljs-params">float2</span> <span class="hljs-params">uv</span>)</span><br><span class="hljs-built_in">float</span> <span class="hljs-constructor">LoadSceneDepth(<span class="hljs-params">uint2</span> <span class="hljs-params">uv</span>)</span><br></code></pre></td></tr></table></figure><ul><li>这两个函数都用于获取深度信息，其区别为：</li><li><ul><li>Texture Sample 是纹理采样，会应用纹理寻址和纹理过滤</li></ul></li><li><ul><li>Texture Load是加载某一特定位置的texel</li></ul></li><li><ul><li>前者使用的是[0,1]范围的浮点数形式的参数</li></ul></li><li><ul><li>后者使用的是[0,textureSizeX&#x2F;Y]范围的整数形式的参数</li></ul></li><li><ul><li><a href="https://gamedev.stackexchange.com/questions/65845/difference-between-texture-load-and-texture-sample-methods-in-directx/65853">Difference between texture.Sample and texture.Load</a></li></ul></li><li>通常gles3.0以上的设备都建议使用LOAD_TEXTURE的方式获取深度值</li></ul><h2 id="DeclareOpaqueTexture-hlsl"><a href="#DeclareOpaqueTexture-hlsl" class="headerlink" title="DeclareOpaqueTexture.hlsl"></a>DeclareOpaqueTexture.hlsl</h2><ul><li>降采样贴图的采样</li><li>里面的两个函数参考深度贴图的采样</li></ul><h2 id="Input-hlsl"><a href="#Input-hlsl" class="headerlink" title="Input.hlsl"></a>Input.hlsl</h2><ul><li>引入了一些常用的变量及函数</li><li>例如：灯光信息、坐标系转换函数、GPUInstancing库</li></ul><h2 id="Lighting-hlsl"><a href="#Lighting-hlsl" class="headerlink" title="Lighting.hlsl"></a>Lighting.hlsl</h2><ul><li>光照计算相关函数</li><li>包含：</li><li><ul><li>URP实现的PBR光照模型、BlinnPhong模型</li></ul></li><li><ul><li>Global Illumination 相关函数</li></ul></li><li><ul><li>BDRF结构</li></ul></li><li><ul><li>Light结构</li></ul></li><li><ul><li>more</li></ul></li></ul><h2 id="Shadows-hlsl"><a href="#Shadows-hlsl" class="headerlink" title="Shadows.hlsl"></a>Shadows.hlsl</h2><ul><li>投影相关函数和结构</li><li>计算各种光的投影强度</li></ul><h2 id="SurfaceInput-hlsl"><a href="#SurfaceInput-hlsl" class="headerlink" title="SurfaceInput.hlsl"></a>SurfaceInput.hlsl</h2><ul><li>定义表面信息的结构和一些帮助函数</li><li>例如：</li><li><ul><li>透明度处理</li></ul></li><li><ul><li>采样反照率透明度</li></ul></li><li><ul><li>采样法线贴图</li></ul></li><li><ul><li>采样自发光</li></ul></li></ul><h2 id="UnityInput-hlsl"><a href="#UnityInput-hlsl" class="headerlink" title="UnityInput.hlsl"></a>UnityInput.hlsl</h2><ul><li>包含了从Unity传入的数据</li></ul><h2 id="MetaInput-hlsl"><a href="#MetaInput-hlsl" class="headerlink" title="MetaInput.hlsl"></a>MetaInput.hlsl</h2><ul><li>MetaPass相关处理函数</li></ul><h2 id="Particles-hlsl"><a href="#Particles-hlsl" class="headerlink" title="Particles.hlsl"></a>Particles.hlsl</h2><ul><li>粒子系统相关函数</li><li>例如：粒子颜色混合、切线空间的法线贴图采样等</li></ul><h2 id="ShaderGraphFunctions-hlsl"><a href="#ShaderGraphFunctions-hlsl" class="headerlink" title="ShaderGraphFunctions.hlsl"></a>ShaderGraphFunctions.hlsl</h2><ul><li>ShaderGraph相关函数</li></ul><h2 id="ShaderTypes-cs-hlsl"><a href="#ShaderTypes-cs-hlsl" class="headerlink" title="ShaderTypes.cs.hlsl"></a>ShaderTypes.cs.hlsl</h2><ul><li>自动生成的文件，不要手动修改</li></ul>]]></content>
    
    
    <categories>
      
      <category>零零散散</category>
      
    </categories>
    
    
    <tags>
      
      <tag>URP</tag>
      
      <tag>Shader</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>光线追踪流程DXR</title>
    <link href="/blog/2022/03/03/short/%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA%E6%B5%81%E7%A8%8BDXR/"/>
    <url>/blog/2022/03/03/short/%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA%E6%B5%81%E7%A8%8BDXR/</url>
    
    <content type="html"><![CDATA[<h1 id="DXR流程图"><a href="#DXR流程图" class="headerlink" title="DXR流程图"></a>DXR流程图</h1><p><img src="/blog/img/DXR.jpeg"></p><ul><li>在DX12的全新图形API中加入了可编程的光线追踪渲染管线，简称DXR。和传统光栅化管线一样，光线追踪的管线有固定的逻辑，也有可编程部分。新管线中新增了5种着色器（Shader）</li></ul><h1 id="可编程着色器"><a href="#可编程着色器" class="headerlink" title="可编程着色器"></a>可编程着色器</h1><h3 id="Ray-Generation："><a href="#Ray-Generation：" class="headerlink" title="Ray Generation："></a>Ray Generation：</h3><ul><li>用于生成射线。在此shader中可以调用TraceRay()递归追踪光线。</li></ul><h3 id="Intersection和Any-Hit："><a href="#Intersection和Any-Hit：" class="headerlink" title="Intersection和Any Hit："></a>Intersection和Any Hit：</h3><ul><li>当TraceRay()内检测到光线与物体相交时，会调用此shader，以便使用者检测此相交的物体是否特殊的图元。</li></ul><h3 id="Closest-Hit和Miss："><a href="#Closest-Hit和Miss：" class="headerlink" title="Closest Hit和Miss："></a>Closest Hit和Miss：</h3><ul><li>当TraceRay()遍历完整个场景后，会根据光线相交与否调用这两个Shader。Closest Hit可以执行像素着色处理，如材质、纹理查找、光照计算等。Closest Hit和Miss都可以继续递归调用TraceRay()。</li></ul><h1 id="Acceleration-Structure"><a href="#Acceleration-Structure" class="headerlink" title="Acceleration Structure"></a>Acceleration Structure</h1><ul><li>光线追踪渲染管线中，还涉及到加速结构（Acceleration Structure）。它的作用是保存场景的所有几何物体信息，在GPU内提供物体遍历、相交测试、光线构造等等的极限加速算法，使得光线追踪达到实时渲染级别。</li></ul>]]></content>
    
    
    <categories>
      
      <category>零零散散</category>
      
    </categories>
    
    
    <tags>
      
      <tag>渲染管线</tag>
      
      <tag>光线追踪</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>渲染合批优化</title>
    <link href="/blog/2022/03/02/short/%E6%B8%B2%E6%9F%93%E4%BC%98%E5%8C%96/"/>
    <url>/blog/2022/03/02/short/%E6%B8%B2%E6%9F%93%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="优化方案"><a href="#优化方案" class="headerlink" title="优化方案"></a>优化方案</h1><ul><li>静态合批</li><li>动态合批</li><li>GPU Instance</li><li>SRP Batcher</li></ul><hr><h2 id="静态合批"><a href="#静态合批" class="headerlink" title="静态合批"></a>静态合批</h2><ul><li>预处理的形式，将一些静态的不常变化的物体进行一次静态的渲染，存储所得数据，空间换时间。</li></ul><h3 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h3><ul><li>需要共享相同的材质，并且不移动、旋转和缩放。</li><li>存在顶点和索引的数量限制。（大部分平台上是64k）</li></ul><h3 id="大致原理"><a href="#大致原理" class="headerlink" title="大致原理"></a>大致原理</h3><ul><li>将GameObject组合成大网格</li></ul><h3 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h3><ul><li>空间换时间，会占用较大内存</li><li>共享相同几何体的模型会出现多个副本提升内存占用，例如密林级别的树木。</li></ul><hr><h2 id="动态合批"><a href="#动态合批" class="headerlink" title="动态合批"></a>动态合批</h2><ul><li>将一些较小的网格在CPU上转换组合，将可混合内容构建为一个较大的顶点缓冲区</li></ul><h3 id="要求-1"><a href="#要求-1" class="headerlink" title="要求"></a>要求</h3><ul><li>顶点数有限制，并且限制很小，编辑器版本不同时限制不同，基本在几百的级别。</li><li>transform中包含镜像的物体会影响动态合批，不深究，注意避免（scale中的某个分量为负数）</li><li>使用多个pass的shader不会被动态合批</li></ul><h3 id="大致原理-1"><a href="#大致原理-1" class="headerlink" title="大致原理"></a>大致原理</h3><ul><li>将可混合内容构建为一个较大的顶点缓冲区VAO</li><li>渲染器为批处理设置材质状态</li><li>将顶点缓冲器绑定到图形设备</li><li>Unity将对应的偏移更新到顶点缓冲区，然后提交绘制调用</li><li>主要优化的是材质状态设置的步骤</li></ul><h3 id="缺陷-1"><a href="#缺陷-1" class="headerlink" title="缺陷"></a>缺陷</h3><ul><li>如今的可应用场景较少，很多情况下有更优的解决方案</li><li>限制较大</li></ul><hr><h2 id="GPU-Instance"><a href="#GPU-Instance" class="headerlink" title="GPU Instance"></a>GPU Instance</h2><ul><li>相同网格的物体，只提交一份原始模型的vbo给gpu，将物体的不同属性抽出来组成buffer发给gpu。</li></ul><h3 id="要求-2"><a href="#要求-2" class="headerlink" title="要求"></a>要求</h3><ul><li>需要模型网格一致</li><li>需要使用同样的材质</li></ul><h3 id="大致原理-2"><a href="#大致原理-2" class="headerlink" title="大致原理"></a>大致原理</h3><ul><li>提交一份基础的模型vbo给gpu</li><li>将物体的不同属性封装为buffer发送给gpu</li><li>gpu使用基础的vbo生成多个实例，并且使用buffer中的属性进行设置</li></ul><h3 id="缺陷-2"><a href="#缺陷-2" class="headerlink" title="缺陷"></a>缺陷</h3><ul><li>在模型比较简单且数量不多时比不上静态合批，因为静态合批是一次draw call一次绘制，而GPU是一次提交多次绘制。</li><li>有需要网格信息和材质都一样的前提（但材质属性可变）</li></ul><hr><h2 id="Unity-SRP-Batcher"><a href="#Unity-SRP-Batcher" class="headerlink" title="Unity SRP Batcher"></a>Unity SRP Batcher</h2><ul><li>Unity缓存了材质信息到GPU缓存中，不必每次渲染都传递材质信息</li></ul><h3 id="要求-3"><a href="#要求-3" class="headerlink" title="要求"></a>要求</h3><ul><li>不可使用非Mesh对象（以后可能支持）</li><li>需要使用兼容的shader（在Inspector中查看）</li><li>使用了MaterialPropertyBlock技术的对象会失效（相当于更改了材质属性）</li></ul><h3 id="大致原理-3"><a href="#大致原理-3" class="headerlink" title="大致原理"></a>大致原理</h3><ul><li>缓存材质信息到GPU中，每次只提交简单的Editor中Inspector中的数据</li><li>使用缓存的材质信息进行渲染</li><li>SRP Batcher本质上不会减少DrawCall，渲染的消耗主要是CPU的数据准备阶段，SRP主要优化的是数据准备的速度，所以DrawCall数量不会变化.</li></ul><h3 id="缺陷-3"><a href="#缺陷-3" class="headerlink" title="缺陷"></a>缺陷</h3><ul><li>需要专门进行shader的编写支持</li><li>需要使用Unity的SRP管线，例如（URP、HDRP等）</li></ul><hr><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.jianshu.com/p/a3087f31ff88">Unity动态合批(Dynamic Batching)与静态合批(Static Batching)</a><br><a href="https://blog.csdn.net/leonwei/article/details/73274808">Unity中基于Gpu Instance进行大量物体渲染的实现与分析（一）</a><br><a href="https://blog.csdn.net/lsjsoft/article/details/90734932">SRP Batcher：提升您的渲染性能</a></p>]]></content>
    
    
    <categories>
      
      <category>零零散散</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Unity渲染优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第十六章-Unity中的渲染优化技术</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0-Unity%E4%B8%AD%E7%9A%84%E6%B8%B2%E6%9F%93%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0-Unity%E4%B8%AD%E7%9A%84%E6%B8%B2%E6%9F%93%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<h2 id="移动平台的特点"><a href="#移动平台的特点" class="headerlink" title="移动平台的特点"></a>移动平台的特点</h2><ul><li>移动平台上的GPU架构专注于尽可能使用更小的带宽和功能。</li><li>为了尽可能移除隐藏的表面，减少overdraw（即一个像素被绘制多次），PowerVR芯片（通常用于iOS和某些Android设备）使用了<strong>基于瓦片的延迟渲染</strong>架构，把所有的渲染图像装入一个个瓦片中，再由硬件找到可见的片元，只有这些可见片元才会执行片元着色器。另一些基于瓦片的GPU架构，Adreno（高通的芯片）和Mali（ARM的芯片）则会使用Early-Z或相似的技术进行一个低精度的深度检测，用来剔除不需要的片元。还有一些GPU，如Tegra（英伟达的芯片），则使用了传统的架构设计，在这些设备上，overdraw更可能造成性能的瓶颈。</li><li>相比Android平台，iOS平台的硬件条件相对统一。Unity手册的<strong>iOS硬件指南</strong>中可以找到相关资料。<h2 id="影响性能的因素"><a href="#影响性能的因素" class="headerlink" title="影响性能的因素"></a>影响性能的因素</h2></li><li>对于一个游戏来说，它主要使用两种计算资源：CPU和GPU。它们互相合作，让我们的游戏可以在预期的<strong>帧率</strong>和<strong>分辨率</strong>下工作。CPU主要保证帧率，GPU主要负责分辨率相关的处理。</li><li>游戏性能瓶颈主要原因可以分为以下几个方面：<h3 id="1-CPU"><a href="#1-CPU" class="headerlink" title="1. CPU"></a>1. CPU</h3><h4 id="过多的draw-call"><a href="#过多的draw-call" class="headerlink" title="过多的draw call"></a>过多的draw call</h4><h4 id="复杂的脚本或者物理模拟"><a href="#复杂的脚本或者物理模拟" class="headerlink" title="复杂的脚本或者物理模拟"></a>复杂的脚本或者物理模拟</h4><h3 id="2-GPU"><a href="#2-GPU" class="headerlink" title="2. GPU"></a>2. GPU</h3><h4 id="顶点处理"><a href="#顶点处理" class="headerlink" title="顶点处理"></a>顶点处理</h4>a.过多的顶点<br>b.过多的逐顶点计算  <h4 id="片元处理"><a href="#片元处理" class="headerlink" title="片元处理"></a>片元处理</h4>a.过多的片元(可能是分辨率造成的，也可能是由于overdraw造成的)<br>b.躲过的逐片元计算  <h3 id="3-带宽"><a href="#3-带宽" class="headerlink" title="3. 带宽"></a>3. 带宽</h3><h4 id="使用了尺寸很大且未压缩的纹理"><a href="#使用了尺寸很大且未压缩的纹理" class="headerlink" title="使用了尺寸很大且未压缩的纹理"></a>使用了尺寸很大且未压缩的纹理</h4><h4 id="分辨率过高的帧缓存"><a href="#分辨率过高的帧缓存" class="headerlink" title="分辨率过高的帧缓存"></a>分辨率过高的帧缓存</h4></li><li>对于CPU来说，限制它的主要是每一帧中的draw call的数目。在第二章中介绍过draw call的相关概念和原理。简单来说，CPU每次通知GPU渲染之前，都需要准备好顶点数据（如位置、法线、颜色、纹理坐标等），然后调用一系列API把它们放到GPU可以访问到的指定位置，最后，调用一个绘制命令告诉GPU开始渲染。调用绘制命令时，就会产生一个draw call。过多的draw call会造成CPU的性能瓶颈，因为每次调用draw call时，CPU往往都需要改变很多渲染状态的设置，而这些操作非常耗时。</li><li>对于GPU来说，它负责整个渲染流水线。从处理CPU传递过来的模型数据开始，进行顶点着色器、片元着色器等一系列工作，最后输出屏幕上的每个像素。因此、GPU的性能瓶颈和需要处理的顶点数目、屏幕分辨率、显存等因素有关。相关的优化策略可以从减少处理的数据规模（包括顶点数目和片元数目）、减少运算复杂度等方面入手。</li><li>之后会涉及的优化技术有：</li></ul><ol><li>CPU优化</li></ol><ul><li>使用批处理技术减少draw call数目</li></ul><ol start="2"><li>GPU优化</li></ol><ul><li>减少需要处理的顶点数目<br>优化几何体<br>使用模型LOD（Level of Detail）技术<br>使用遮挡剔除（Occlusion Culling）技术  </li><li>减少需要处理的片元数目<br>控制绘制顺序<br>警惕透明物体<br>减少实时光照</li><li>减少计算复杂度<br>使用shader的LOD技术<br>代码方面的优化</li></ul><ol start="3"><li>节省内存带宽</li></ol><ul><li><p>减少纹理大小</p></li><li><p>利用分辨率缩放  </p></li><li><p>在开始优化之前，我们首先需要知道是那个步骤造成了性能瓶颈。而这可以利用Unity提供的一些渲染分析工具来实现。</p></li></ul><h2 id="Unity中的渲染分析工具"><a href="#Unity中的渲染分析工具" class="headerlink" title="Unity中的渲染分析工具"></a>Unity中的渲染分析工具</h2><ul><li>Unity内置了一些工具帮助我们查看和渲染相关的各个统计数据。这些数据可以帮助我们分析游戏渲染性能，从而有针对性地进行优化。这些工具包括渲染统计窗口（Rendering Statistics Window）、性能分析器（Profiler），以及帧调试器（Frame Debugger）。</li></ul><h3 id="认识Unity-5的渲染统计窗口"><a href="#认识Unity-5的渲染统计窗口" class="headerlink" title="认识Unity 5的渲染统计窗口"></a>认识Unity 5的渲染统计窗口</h3><ul><li>通过Game视图右上角的Stats按钮来打开</li><li>渲染统计窗口主要包含3个方面的信息：音频（Audio）、图像（Graphics）和网络（Network）。我们这里只关注图像方面</li></ul><table><thead><tr><th>信息名称</th><th>描述</th></tr></thead><tbody><tr><td>每帧的时间和FPS</td><td>在Graphic的右侧显示，给出了处理和渲染一帧所需的时间，以及FPS数目。</td></tr><tr><td>Batches</td><td>一帧中需要进行的批处理数目</td></tr><tr><td>Saved by batching</td><td>合并的批处理数目，这个数字表明了批处理为我们节省了多少draw call</td></tr><tr><td>Tris和Verts</td><td>需要绘制的三角面片和顶点数目</td></tr><tr><td>Screen</td><td>屏幕的大小，以及它占用的内存大小</td></tr><tr><td>SetPass</td><td>渲染使用的Pass的数目，每个Pass都需要Unity的runtime来绑定一个新的Shader，这可能造成CPU的瓶颈。</td></tr><tr><td>Visible Skinned Meshes</td><td>渲染的蒙皮网格的数目</td></tr><tr><td>Animations</td><td>播放的动画数目</td></tr></tbody></table><h3 id="性能分析器的渲染区域"><a href="#性能分析器的渲染区域" class="headerlink" title="性能分析器的渲染区域"></a>性能分析器的渲染区域</h3><ul><li>通过单击Window-&gt;Profiler来打开Unity的<strong>性能分析器</strong>。性能分析器中的渲染区域（Rendering Area）提供了更多关于渲染的统计信息。</li><li>结合渲染统计窗口和性能分析器，我们可以查看与渲染相关的绝大多数重要的数据。<h3 id="再谈帧调试器"><a href="#再谈帧调试器" class="headerlink" title="再谈帧调试器"></a>再谈帧调试器</h3></li><li>通过Window-&gt;Frame Debugger来打开它。</li><li>这个窗口我们可以清楚地看到每一个draw call的工作结果。</li></ul><h3 id="其他性能分析工具"><a href="#其他性能分析工具" class="headerlink" title="其他性能分析工具"></a>其他性能分析工具</h3><ul><li>对于移动平台，我们更希望获得真机上运行游戏时的性能数据。</li><li>对于Android平台来说，高通的Adreno分析工具可以对不同的测试机进行详细的性能分析。英伟达提供了NVPerfHUD工具来帮助我们得到几乎所有的性能分析数据。例如，每个draw call的GPU时间，每个shader花费的cycle数目等。</li><li>对于iOS平台来说，Unity内置的分析器可以得到整个场景花费的GPU时间。PowerVRAM的PVRUniSCo shader分析器也可以给出大致的性能评估。Xcode中的OpenGL ES Driver Instruments可以给出一些宏观的性能信息，例如设备利用率，渲染器利用率等。相对于Android平台，iOS平台性能分析更加困难（工具较少）。</li></ul><h2 id="减少draw-call数目"><a href="#减少draw-call数目" class="headerlink" title="减少draw call数目"></a>减少draw call数目</h2><ul><li>批处理的实现原理就是为了减少每一帧需要的draw call数目。把一个对象渲染到屏幕上，CPU需要检查哪些光源影响了该物体，绑定shader并设置它的参数，再把渲染命令发送到GPU。场景中包含大量对象时，这些操作就会非常耗时。</li></ul><h3 id="动态批处理"><a href="#动态批处理" class="headerlink" title="动态批处理"></a>动态批处理</h3><ul><li>如果场景中有一些模型共享了同一个材质并满足一些条件，Unity就可以自动把它们进行批处理，从而花费一个draw call就可以渲染所有的模型。动态批处理每帧都把可以批处理的网格合并传给GPU。动态批处理好处在于物体仍可以移动。</li><li>主要限制条件：</li></ul><ol><li>能够进行动态批处理的网格的顶点属性规模要小于900（将来这个数字可能会发生变化）</li><li>使用光照纹理（lightmap）的物体需要保证它们指向光照纹理中的同一位置。</li><li>多Pass的shader会中断批处理。<h3 id="静态批处理"><a href="#静态批处理" class="headerlink" title="静态批处理"></a>静态批处理</h3></li></ol><ul><li>使用于任何大小的几何模型。</li><li>只在运行开始阶段，把需要进行静态批处理的模型合并到一个新的网格中，这意味着这些模型不可以在运行时被移动。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第十五章-使用噪声</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0-%E4%BD%BF%E7%94%A8%E5%99%AA%E5%A3%B0/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0-%E4%BD%BF%E7%94%A8%E5%99%AA%E5%A3%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="消融效果"><a href="#消融效果" class="headerlink" title="消融效果"></a>消融效果</h2><ul><li><strong>消融</strong>效果常见于游戏中的角色死亡、地图烧毁等效果。</li><li>原理十分简单，概括来说就是使用噪声纹理+透明度测试。我们使用噪声纹理采样的结果与某个阈值比较，如果小于阈值，就是用clip函数把对应的像素减掉，这些部分就对应了被“烧毁”的区域。镂空区域边缘的烧焦效果是将两种颜色混合，再用pow函数处理后，与原纹理颜色混合后的结果。</li><li>使用不同的噪声和纹理属性（材质面板上的Tiling和Offset值）都会得到不同的消融效果。想要得到好的消融效果，也需要美术人员提供合适的噪声纹理来配合。</li></ul><h2 id="水波效果"><a href="#水波效果" class="headerlink" title="水波效果"></a>水波效果</h2><ul><li>模拟实时水面时，我们也会使用噪声纹理。此时噪声通常会作为一个高度图，不断修改水面的法线方向。为了模拟水不断流动的效果，还会使用和时间相关的变量对噪声纹理进行采样，得到法线信息后，再进行正常的反射+折射计算，得到最后的水面波动效果。</li><li></li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第十四章-非真实感渲染</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0-%E9%9D%9E%E7%9C%9F%E5%AE%9E%E6%84%9F%E6%B8%B2%E6%9F%93/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0-%E9%9D%9E%E7%9C%9F%E5%AE%9E%E6%84%9F%E6%B8%B2%E6%9F%93/</url>
    
    <content type="html"><![CDATA[<ul><li>尽管游戏渲染一般都是以<strong>照相写实主义</strong>作为主要目标。但也有许多游戏使用了<strong>非真实感渲染</strong>的方法来渲染游戏画面。</li><li>非真实感渲染的目标是使用一些渲染方法，使得画面达到和某些特殊的绘画风格相似的效果。例如：卡通、水彩风格。</li></ul><h2 id="卡通风格的渲染"><a href="#卡通风格的渲染" class="headerlink" title="卡通风格的渲染"></a>卡通风格的渲染</h2><ul><li>实现卡通渲染有很多方法，其中之一就是基于色调的光照模型。</li><li>在实现中，我们往往会使用一张一维纹理进行采样，以控制漫反射的色调。</li><li>卡通风格的高光效果也和我们之前学习的光照不同，卡通风格中，模型的高光往往是一块块分界明显的纯色区域。</li><li>卡通风格通常还需要在物体边缘部分绘制轮廓</li></ul><h3 id="渲染轮廓线"><a href="#渲染轮廓线" class="headerlink" title="渲染轮廓线"></a>渲染轮廓线</h3><p>有许多轮廓线的渲染方法被提出，这里介绍其中五种：</p><ul><li>基于观察角度和表面法线的轮廓线渲染。使用视角方向和表面法线的点乘结果来得到轮廓线的信息。这种方法简单快速，一个Pass中就可以得到渲染结果，但局限性很大，很多模型渲染出来的描边效果不尽如人意。</li><li>过程式几何轮廓线渲染。使用两个Pass渲染，第一个Pass渲染背面的面片，并使用某些技术让它的轮廓可见；第二个Pass再正常渲染正面的面片。这种方法有点在于快速有效，并且适用于绝大多数表面光滑的模型，但它的缺点是不适合类似正方体这类表面平整的模型。</li><li>基于图像处理的轮廓线渲染。之前边缘检测的方法就属于这个类别。这种方法有点在于可以适用于任何类型的模型。但也有局限性，一些深度和法线变化很小的轮廓无法被检测出来，例如桌子上的纸张。</li><li>基于轮廓边检测的轮廓线渲染。上述提到的方法无法控制轮廓线的风格渲染。我们检测一条边是否是轮廓边的公式很简单：<figure class="highlight gcode"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs gcode"><span class="hljs-comment">(n0·v&gt;0)</span> ≠ <span class="hljs-comment">(n1·v&gt;0)</span><br></code></pre></td></tr></table></figure></li><li>其中n0和n1是相邻两个三角面片的法向量，v是视角到该边上任意顶点的方向。检测出两个三角面是否一个朝正面，一个朝背面。我们可以再几何着色器的帮助下实现检测过程。</li><li>最后一个种类就是混合了上述的几种渲染方法。例如，首先找到精确的轮廓边，把模型和轮廓边渲染到纹理中，再使用图像处理的方法识别出轮廓线，并在图像空间下进行风格化渲染。<h3 id="添加高光"><a href="#添加高光" class="headerlink" title="添加高光"></a>添加高光</h3></li><li>计算normal和halfDir的点乘结果，把该值和一个阈值进行比较，如果小于该阈值，高光反射系数为0，否则返回1；<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">float spec</span> = dot(worldNormal,worldHalfDir);<br><span class="hljs-attribute">spec</span> = step(threshold,spec);<br></code></pre></td></tr></table></figure></li><li>系数直接突变会使边界处产生锯齿，我们可以在边界处很小的一块区域内，进行平滑处理。<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">float spec</span> = dot(worldNormal,worldHalfDir);<br><span class="hljs-attribute">spec</span> = smoothstep(-w,w,spec - threshold);<br></code></pre></td></tr></table></figure></li></ul><h2 id="像素风格的渲染"><a href="#像素风格的渲染" class="headerlink" title="像素风格的渲染"></a>像素风格的渲染</h2><ul><li>使用了提前生成的素描纹理来实现实时的素描风格渲染，这些纹理组成了一个<strong>色调艺术映射</strong><br><img src="https://img-blog.csdnimg.cn/20190507110327608.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDg2NjM5,size_16,color_FFFFFF,t_70" alt="TAM例子">  </li><li>图中从左到右纹理中的笔触逐渐增多，用于模拟不同光照下的漫反射效果。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第十三章-使用深度法线和纹理</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0-%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E6%B3%95%E7%BA%BF%E5%92%8C%E7%BA%B9%E7%90%86/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0-%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E6%B3%95%E7%BA%BF%E5%92%8C%E7%BA%B9%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="获取深度和法线纹理"><a href="#获取深度和法线纹理" class="headerlink" title="获取深度和法线纹理"></a>获取深度和法线纹理</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><h4 id="深度纹理"><a href="#深度纹理" class="headerlink" title="深度纹理"></a>深度纹理</h4><ul><li>就是一张渲染纹理，存储的像素值是高精度的深度值。</li><li>范围是[0,1]，通常是非线性分布的。</li><li>深度值来自于顶点变换后得到的归一化的设备坐标</li><li>顶点转换到齐次裁剪空间后，z坐标就是它的深度值。但是z分量的范围是[-1,1]所以我们为了能将其存储在图像中，使用：<br>d &#x3D; 0.5*z + 0.5<br>将其变为[0,1]范围中。</li><li>Unity中深度纹理可以来自于真正的深度缓存，也可以由单独一个Pass渲染获得，这取决于渲染路径和硬件。</li><li>使用延迟渲染路径可以直接从G-buffer中获得深度信息。</li><li>当无法直接获取深度缓存时，深度和法线纹理是通过一个单独的Pass渲染获得。</li><li>具体实现是，Unity会使用<strong>着色器替换</strong>技术选择渲染类型为Opaque的物体，判断它使用的渲染队列是否小于2500（包括Background、Geometry和AlphaTest），如果满足条件就把他渲染到深度和法线纹理中。</li><li>在Unity中，我们可以选择让一个摄像机生成一张深度纹理或是一张深度+法线纹理。</li><li>选择前者时，Unity会直接获得深度缓存或者按之前讲到的着色器替换技术，使用物体投射阴影时使用的Pass来获取深度纹理。如果shader中不包含这样的pass，那么物体就不会出现在深度纹理中。深度纹理的精度通常是24位或者16位，这取决于深度缓存的精度。</li><li>如果选择生成一张深度+法线纹理，Unity会创建一张和屏幕分辨率相同、精度为32位的纹理，其中观察空间下的法线信息会被编码进纹理的R和G通道，深度信息会被编码进B和A通道。法线信息在延迟渲染路径下很容易获取，将法线和深度缓存合并即可。在前向渲染中，默认情况下不会创建法线缓存，因此Unity底层使用一个单独的Pass把整个场景再次渲染一遍来完成。这个Pass被包含在Unity内置的一个Unity Shader中，可以在builtin_shaders-xxx&#x2F;DefaultResources&#x2F;Camera-DepthNormalTexture.shader文件中找到这个用于渲染深度和法线信息的Pass。</li></ul><h3 id="如何获取"><a href="#如何获取" class="headerlink" title="如何获取"></a>如何获取</h3><ul><li>获取深度纹理十分简单，在脚本中设置摄像机的depthTextureMode来完成：<figure class="highlight ini"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">camera.depthTextureMode</span> = DepthTextureMode.Depth<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure></li><li>之后在shader中声明_CameraDepthTexture变量来访问它。</li><li>同理，获取深度+法线纹理，我们只需要在代码中设置：<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">camera.depthTextureMode</span> = DepthTextureMode.DepthNormals<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure></li><li>之后在shader中声明_CameraDepthNormalTexture变量来访问它。</li><li>通常情况下，我们直接使用tex2D对纹理进行采样即可，但在某些平台上（例如PS3和PS2），我们需要一些特殊处理。Unity为我们提供了一个统一的宏，SAMPLE_DEPTH_TEXTURE来处理这些平台差异。<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-built_in">float</span> d = <span class="hljs-constructor">SAMPLE_DEPTH_TEXTURE(<span class="hljs-params">_CameraDepthTexture</span>,<span class="hljs-params">i</span>.<span class="hljs-params">uv</span>)</span>;<br></code></pre></td></tr></table></figure></li><li>i.uv是一个float2类型的变量，对应了当前像素的纹理坐标。</li><li>类似的宏还有SAMPLE_DEPTH_TEXTURE_PROJ，同样接受两个参数，第二个参数是一个float3或者float4类型的纹理坐标，前两个分量是uv坐标，会使用前两个分量除以第三个分量再进行采样，如果提供第四个分量，会再进行一次比较，通常用于阴影的实现中。<br>例如：<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-built_in">float</span> d = <span class="hljs-constructor">SAMPLE_DEPTH_TEXTURE_PROJ(<span class="hljs-params">_CameraDepthTexture</span>,UNITY_PROJ_COORD(<span class="hljs-params">i</span>.<span class="hljs-params">srcPos</span>)</span>);<br></code></pre></td></tr></table></figure></li><li>i.srcPos是顶点着色器中通过调用ComputerScreenPos(o.pos)得到的屏幕坐标。</li><li>取样得到的z分量是非线性的，我们需要把它转换到线性空间中，例如视角空间。</li><li>齐次裁剪空间转换到视角空间的方法可以由视角空间到齐次裁剪空间的公式逆推得到。</li><li>Unity提供了两个辅助函数来为我们进行上述的计算过过程：LinearEyeDepth和Linear01Depth。</li><li><strong>LinearEyeDepth</strong>负责把采样获得的深度值转换到观察空间下的深度值</li><li><strong>Linear01Dept</strong>h则会返回一个范围在[0,1]的线性深度值。</li><li>两个函数使用了内置变量_ZBufferParams变量来得到远近裁剪平面的距离。</li><li>如果我们需要获得深度+法线纹理，可以tex2D函数对_CameraDepthNormalTexture进行采样。</li><li>Unity提供了辅助函数DecodeDeothNormal对采样结果进行解码：<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">inline void <span class="hljs-constructor">DecodeDepthNormal(<span class="hljs-params">float4</span> <span class="hljs-params">enc</span>,<span class="hljs-params">out</span> <span class="hljs-params">float</span> <span class="hljs-params">depth</span>,<span class="hljs-params">out</span> <span class="hljs-params">float3</span> <span class="hljs-params">normal</span>)</span>&#123;<br>    depth = <span class="hljs-constructor">DecodeFloatRG(<span class="hljs-params">enc</span>.<span class="hljs-params">zw</span>)</span>;<br>    normal = <span class="hljs-constructor">DecodeViewNormalStereo(<span class="hljs-params">enc</span>)</span>;<br>&#125;<br></code></pre></td></tr></table></figure></li><li>第一个参数是对深度法线纹理的采样结果，这个结果是Unity对深度法线信息进行了编码后的结果，xy分量存储的是视角空间下的法线信息，而深度信息被编码进了zw分量。调用辅助函数后就可以得到解码后的深度和法线信息了。这个深度值是范围在[0,1]的线性深度值（与单独的深度纹理中存储的深度值不同），得到的法线则是视角空间下的法线方向。同样，我们也可以通过调用DecodeFloatRG和DecodeViewNormalStereo来解码深度+法线纹理中的深度和法线信息。</li></ul><h3 id="查看深度和法线纹理"><a href="#查看深度和法线纹理" class="headerlink" title="查看深度和法线纹理"></a>查看深度和法线纹理</h3><ul><li>在设置了摄像机渲染深度和法线纹理后可以在Frame Debug中查看。</li><li>单独深度纹理展示的是非线性空间下的深度值；深度加法线纹理展示的是编码以后的结果。</li><li>我们可以编写shader来显示线性空间或者解码后的结果。</li></ul><h2 id="再谈运动模糊"><a href="#再谈运动模糊" class="headerlink" title="再谈运动模糊"></a>再谈运动模糊</h2><ul><li>运动模糊更广泛的技术是使用速度映射图。速度映射图存储了每个像素的速度，然后使用这个速度来决定模糊的大小和方向。</li><li>速度缓冲生成的方法很多。一种是把场景中所有物体速度渲染到一张纹理中。这种方法缺点是在于需要修改场景中所有物体的shader代码，使其添加计算速度的代码并输出到一个渲染纹理中。</li><li>《GPU Gems3》中介绍了一种生成速度映射图的方法。这种方法利用深度纹理在片元着色器中为每个像素计算其在世界空间下的位置，通过使用当前视角*投影矩阵的逆矩阵对NDC下的顶点坐标进行变换得到的。用相同方法得到前一帧中该位置的NDC坐标。然后对其求差值，生成该像素的速度。优点是在屏幕后处理时完成了整个效果的模拟；缺点是需要在片元着色器中进行两次矩阵乘法的操作，对性能有所影响。</li></ul><h2 id="全局雾效"><a href="#全局雾效" class="headerlink" title="全局雾效"></a>全局雾效</h2><ul><li><strong>雾效</strong>是游戏里经常使用的一种效果。Unity内置的雾效可以产生基于距离的线性或指数雾效。想要在自己编写的顶点&#x2F;片元着色器中实现这些雾效，我们需要在Shader中添加#pragma multi_compile_fog指令，同时还需要使用相关内置宏，例如UNITY_FOG_COORDS、UNITY_TRANSFER_FOG 和 UNITY_APPLY_FOG等。</li><li>这种方法的缺点在于，我们不仅需要为场景中的所有物体添加相关渲染代码，而且能够给实现的效果也非常有限。</li><li>我们将学习一种基于屏幕后处理的全局雾效。这种方法可以方便地模拟各种雾效。</li><li>基于屏幕后处理的全局雾效的关键是，根据深度纹理来重建每个像素在世界空间下的位置。</li><li>重建方法：（比运动模糊中的更效率）对图像空间下的视锥体射线（从摄像机出发，指向图像上某点的射线）进行插值，这条射线存储了该像素在世界空间下到摄像机的方向信息。然后我们把该射线和线性化后的视角空间下的深度值相乘，再加上摄像机的世界位置，就可以得到该像素在世界空间下的位置。当我们得到世界坐标后，就可以使用各个公式来模拟全局雾效了。</li></ul><h2 id="再谈边缘检测"><a href="#再谈边缘检测" class="headerlink" title="再谈边缘检测"></a>再谈边缘检测</h2><ul><li>之前我们使用的是Sobel算子，根据颜色来进行边缘检测实现描边效果。但是会得到许多我们不希望得到的边缘线。</li><li>我们将要使用深度和法线纹理进行边缘检测。</li><li>本节会使用Roberts算子进行边缘检测。</li><li>通过纹理采样，获取比较当前片元的左上与右下、左下与右上的片元的法线与深度值的相差大小，如果高于某个阈值，则认为这是一条边。这样的方法相对基于颜色的边缘检测更加精确。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第十二章-屏幕后处理效果</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0-%E5%B1%8F%E5%B9%95%E5%90%8E%E5%A4%84%E7%90%86%E6%95%88%E6%9E%9C/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0-%E5%B1%8F%E5%B9%95%E5%90%8E%E5%A4%84%E7%90%86%E6%95%88%E6%9E%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="建立一个基本的屏幕后处理脚本系统"><a href="#建立一个基本的屏幕后处理脚本系统" class="headerlink" title="建立一个基本的屏幕后处理脚本系统"></a>建立一个基本的屏幕后处理脚本系统</h2><ul><li>屏幕后处理，通常指的是在渲染完整个场景得到屏幕图像后，再对这个图像进行一系列操作，实现各种屏幕特效。可以为游戏画面添加更多的艺术效果，例如景深、运动模糊。</li><li>要实现屏幕后处理的基础在于得到渲染后的屏幕图像吗，即抓取平屏幕，Unity为我们提供了这样一个函数：</li></ul><p><strong>MonoBehaviour.OnRenderImage(RenderTexture src,RenderTexture dest)</strong>  </p><ul><li>声明此函数后，unity会将屏幕图像存储在第一个参数对应的源渲染纹理中，通过函数一系列操作后，再把第二个参数对应的渲染纹理显示到屏幕上。</li><li>我们通常是利用Graphics.Blit函数来完成对渲染纹理的处理，函数的3中声明：<br>public static void Blit(Texture src,RenderTexture dest);<br>public static void Blit(Texture src,RenderTexture dest,Material mat,int pass &#x3D; -1);<br>public static void Blit(Texture src,Material,int pass &#x3D; -1);  </li><li>src:原纹理，通常是当前屏幕的渲染纹理或者上一步处理后得到的渲染纹理。</li><li>dst:目标渲染纹理，值为null就会直接渲染到屏幕上。</li><li>mat:是我们使用的材质，这个材质使用的Unity Shader将会进行各种屏幕后处理操作，src会被传递给Shader中名为_MainTex的纹理属性。</li><li>pass:默认为-1，表示会依次调用shader中的所有pass。否则调用指定索引的pass。</li><li>默认情况下，OnRenderImage会在所有透明、不透明物体渲染之后调用，以便渲染所有物体</li><li>通常后处理的步骤：</li></ul><ol><li>在摄像机中添加一个屏幕后处理脚本。</li><li>脚本中实现OnRenderImage函数来获取当前的屏幕渲染纹理。</li><li>调用Graphics.Blit函数使用特定的Unity Shader来对当前图像进行处理，再将返回的渲染纹理显示到屏幕上。</li><li>一些复杂的屏幕特效可能多次调用Graphics.Blit函数对上一步的输出结果进行下一次处理。</li></ol><ul><li>屏幕后处理之前，需要进行检查。例如当前平台是否支持纹理渲染和屏幕特效，或者是否支持使用Unity Shader。因此我们要创建一个用于屏幕后处理效果的基类。</li></ul><h2 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h2><ul><li>边缘检测的原理是利用一些边缘检测算子对图像进行<strong>卷积</strong>操作。</li><li>图像处理中，卷积操作指的就是使用一个<strong>卷积核</strong>对一张图像中的每个像素进行一系列操作。卷积核通常是一个四方形网格结构，该区域每个方格都有一个权重值。当对图像中某个像素进行卷积时，我们会把卷积核的中心放置于这个像素上，翻转核之后再依次计算核中每个元素和其覆盖的图像像素值的乘积并求和，得到的结果就是该位置的新像素值。</li></ul><h3 id="常见的边缘检测算子"><a href="#常见的边缘检测算子" class="headerlink" title="常见的边缘检测算子"></a>常见的边缘检测算子</h3><ul><li>用于边缘检测的卷积核也被称为边缘检测算子。</li><li>如果相邻像素之间存在差别明显的颜色、亮度、纹理等属性，我们就会认为它们之间应该有一条边界。这种相邻像素之间的插值可以用<strong>梯度</strong>来表示。<br><img src="https://img-blog.csdnimg.cn/20190502224814967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDg2NjM5,size_16,color_FFFFFF,t_70" alt="边缘检测算子">  </li><li>它们都包含了两个方向的卷积核，分别用于检测水平方向和竖直方向上的边缘信息。在进行边缘检测时，我们需要对每个像素进行一次卷积计算，得到两个方向上的梯度值Gx和Gy，而整体的梯度按照下面公式计算：<br><img src="https://img-blog.csdnimg.cn/20190502225140970.png" alt="梯度值计算公式"></li></ul><h2 id="高斯模糊"><a href="#高斯模糊" class="headerlink" title="高斯模糊"></a>高斯模糊</h2><ul><li>卷积的另一个常见应用就是高斯模糊。模糊实现的方法有很多，例如均值模糊和中值模糊。</li><li>均值模糊：卷积核中的各个元素都相等，并且相加等于1，也就是卷积后的像素值是其邻域内像素值得和。</li><li>中值模糊：选择邻域内对所有像素排序后的中值替换原颜色。</li><li>高斯模糊是一个更高级的模糊方法。<h3 id="高斯滤波"><a href="#高斯滤波" class="headerlink" title="高斯滤波"></a>高斯滤波</h3></li><li>高斯模糊使用的卷积核名为高斯核。</li><li>高斯核是一个正方形大小的滤波核，其中每个元素都基于下面的高斯方程：<br><img src="https://img-blog.csdnimg.cn/20190503205631803.png" alt="高斯方程">  </li><li>σ是标准方差（一般取1）</li><li>x和y分别对应了当前位置到卷积核中心的整数距离。</li><li>我们需要对高斯核中的权重进行归一化，这样图像才不会变暗。因此e前面的系数不会对实际结果有任何影响。</li><li>高斯方程很好地模拟了邻域每个像素对当前像素的影响程度——距离越近，影响越大。高斯核的维数越高，模糊程度越大。使用NxN的高斯核，就需要NxNxWxH（W和H为图像的宽和高）次纹理采样。</li><li>但我们可以把二维的高斯核拆成两个一维的高斯核，得到的结果是一样的，采样次数大大减少。</li><li>我们会使用先后两个Pass，第一个Pass将会使用竖直方向的一维高斯核对图像进行滤波，第二个Pass再使用水平方向的一维高斯核对图像进行滤波，得到最终的目标图像。</li><li>在实现中，我们还将利用图像缩放进一步提高性能，并通过高斯滤波的应用次数来控制模糊程度。（次数越多图像越模糊）</li></ul><h2 id="Bloom效果"><a href="#Bloom效果" class="headerlink" title="Bloom效果"></a>Bloom效果</h2><ul><li>游戏中一种常见特效</li><li>模拟真实摄像机的一种图像效果，让画面中比较亮的区域“扩散”到周围的区域中，造成朦胧的效果。</li><li>原理：首先根据一个阈值提取出图像中的较亮区域，把它们存储在一张渲染纹理中，利用高斯模糊对这张渲染纹理进行模糊处理，模拟光线的扩散效果，最后将其与原图混合，得到最终效果。</li></ul><h2 id="运动模糊"><a href="#运动模糊" class="headerlink" title="运动模糊"></a>运动模糊</h2><ul><li>模拟真实世界中的摄像机的一种效果。如果在摄像机曝光时，拍摄场景发生了变化，就会产生模糊画面。</li><li>运动模糊效果可以让物体运动看起来更加真实平滑。</li><li>运动模糊有多种实现方法：</li><li>一种实现方法是利用一块<strong>累计缓存</strong>来混合多张连续的图像。物体快速移动产生多张图像后，我们取它们之间的平均值作为最后的运动模糊图像。缺点是性能消耗大，想要获取多张帧图像意味着需要在同一帧里渲染多次场景。</li><li>另一种广泛的方法是使用<strong>速度缓存</strong>，这个缓存中存储了各个像素当前的运动速度，然后利用该值来决定模糊的方向和大小。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第十一章-让画面动起来</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0-%E8%AE%A9%E7%94%BB%E9%9D%A2%E5%8A%A8%E8%B5%B7%E6%9D%A5/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0-%E8%AE%A9%E7%94%BB%E9%9D%A2%E5%8A%A8%E8%B5%B7%E6%9D%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="Unity-Shader中的内置变量（时间篇）"><a href="#Unity-Shader中的内置变量（时间篇）" class="headerlink" title="Unity Shader中的内置变量（时间篇）"></a>Unity Shader中的内置变量（时间篇）</h2><ul><li>Unity Shader提供了一系列关于时间的内置变量来允许我们在Shader中访问运行时间，实现各种动画效果。<h4 id="Unity内置的时间变量"><a href="#Unity内置的时间变量" class="headerlink" title="Unity内置的时间变量"></a>Unity内置的时间变量</h4></li></ul><table><thead><tr><th>名称</th><th>类型</th><th>描述</th></tr></thead><tbody><tr><td>_Time</td><td>float4</td><td>t是自该场景加载开始所经过的时间，4个分量的值分别是(t&#x2F;20,t,2t,3t)。</td></tr><tr><td>_SinTime</td><td>float4</td><td>t是时间的正弦值，4个分量的值分别是(t&#x2F;8,t&#x2F;4,t&#x2F;2,t)。</td></tr><tr><td>_CosTime</td><td>float4</td><td>t是时间的余弦值，4个分量的值分别是(t&#x2F;8,t&#x2F;4,t&#x2F;2,t)。</td></tr><tr><td>unity_DeltaTime</td><td>float4</td><td>dt是时间增量，4个分量的值分别是(dt,1&#x2F;dt,smoothDt,1&#x2F;smoothDt)</td></tr></tbody></table><h2 id="纹理动画"><a href="#纹理动画" class="headerlink" title="纹理动画"></a>纹理动画</h2><ul><li>在各种资源都比较局限的移动平台上，我们甚至可以用纹理动画代替复杂的粒子系统。</li></ul><h3 id="序列帧动画"><a href="#序列帧动画" class="headerlink" title="序列帧动画"></a>序列帧动画</h3><ul><li>一次播放一系列关键帧图像，播放速度达到一定数值时，看起来就是一个连续的动画。</li><li>优点是灵活性强，不需要任何计算就可以得到非常细腻的动画。</li><li>缺点是制作一张出色的序列帧纹理需要的美术工程量也很大。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第十章-高级纹理</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E7%AB%A0-%E9%AB%98%E7%BA%A7%E7%BA%B9%E7%90%86/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%8D%81%E7%AB%A0-%E9%AB%98%E7%BA%A7%E7%BA%B9%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="立方体纹理"><a href="#立方体纹理" class="headerlink" title="立方体纹理"></a>立方体纹理</h2><ul><li><strong>环境映射</strong>的一种实现方式。</li><li>包含六张图像，对应立方体六个面。</li><li>纹理采样需要提供一个三维坐标，坐标作为一个矢量从立方体中心出发，采样结果就是矢量与立方体表面交点的信息。</li><li>优点：实现简单，得到的效果好。</li><li>缺点：引入新的物体、光源，或者物体发生移动时，需要重新生成。</li><li>常用与天空盒以及环境映射。<h3 id="天空盒"><a href="#天空盒" class="headerlink" title="天空盒"></a>天空盒</h3></li><li>模拟天空或室内等背景</li><li>Unity中，天空盒是在所有不透明物体之后渲染的。<h3 id="用于环境映射的立方体纹理"><a href="#用于环境映射的立方体纹理" class="headerlink" title="用于环境映射的立方体纹理"></a>用于环境映射的立方体纹理</h3></li><li>Unity5中创建用于环境映射的立方体纹理的方法：</li></ul><ol><li>直接由特殊布局的纹理生成<br>需要一张具有特殊布局，类似立方体展开的交叉布局、全景布局。把纹理的Texture Type设置为Cubemap即可。</li><li>手动创建一个Cubemap资源，再给它添加6张图<br>与天空盒材质创建相同。Unity5后建议使用第一种方式，方便压缩、边缘修正、光滑反射和HDR</li><li>由脚本生成。<br>前两种方法需要提供提前准备好的纹理图像。Unity中可以使用<strong>Camera.RenderToCubemap</strong>函数把从任意位置观察到的图像存储到6张图像中，从而创建出对应位置上的立方体纹理。</li></ol><h4 id="反射"><a href="#反射" class="headerlink" title="反射"></a>反射</h4><ul><li>因为光线可逆，我们通过视角方向（指向表面）和表面法线可以计算出入射光线的方向，通过这个方向对纹理进行采样就可以得到反射信息。</li></ul><h4 id="折射"><a href="#折射" class="headerlink" title="折射"></a>折射</h4><ul><li>当光线从一种介质斜射入另一种介质时，传播方向一般会发生改变。</li><li>给定入射角时，我们可以使用<strong>斯涅尔定律</strong>来计算反射角。</li><li>光从介质1沿着和表面法线夹角为θ<sub>1</sub>的方向斜射入介质2时，我们可以使用如下公式计算折射光线与法线的夹角θ<sub>2</sub>：</li></ul><p><strong>η<sub>1</sub>sinθ<sub>1</sub>&#x3D;η<sub>2</sub>sinθ<sub>2</sub></strong><br>η<sub>1</sub>、η<sub>2</sub>分别为两个介质的<strong>折射率（index of refraction）</strong><br><img src="https://img-blog.csdnimg.cn/20190426220743848.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDg2NjM5,size_16,color_FFFFFF,t_70" alt="斯涅尔定律图解">  </p><h4 id="菲涅尔反射"><a href="#菲涅尔反射" class="headerlink" title="菲涅尔反射"></a>菲涅尔反射</h4><ul><li>根据视角方向控制反射程度。  </li><li>关于菲涅尔反射，建议看看这个网站：<br><a href="http://gad.qq.com/program/translateview/7195431">万物皆有菲涅尔反射</a>  </li><li>Schilck菲涅尔近似等式：<br>F<sub>schilk</sub>(<strong>v</strong>,<strong>n</strong>)&#x3D;F<sub>0</sub>+(1-F<sub>0</sub>)(1-<strong>v</strong>·<strong>n</strong>)<sup>5</sup><br>其中F<sub>0</sub>为反射系数，用于控制反射强度，<strong>v</strong>是视角方向，<strong>n</strong>是表面法线。</li><li>Empricial 菲涅尔近似等式：<br>F<sub>Empricial</sub>(<strong>v</strong>,<strong>n</strong>)&#x3D;max(0,min(1,bias+scale×(1-<strong>v</strong>·<strong>n</strong>)<sup>power</sup>))<br>其中bias、scale和power都是控制项。</li></ul><h2 id="渲染纹理"><a href="#渲染纹理" class="headerlink" title="渲染纹理"></a>渲染纹理</h2><ul><li>之前学习中，一个摄像机的渲染结果会输出到颜色缓冲中。现在GPU允许我们把整个三维场景渲染到一个中间缓冲中，即<strong>渲染目标纹理（Render Target Texture，RTT）</strong>，而不是传统的帧缓冲或后备缓冲。</li><li>与之相关的是<strong>多冲渲染目标（Multiple Render Target，MRT）</strong>，允许我们把场景同时渲染到多个目标纹理中。</li><li>Unity专门定义了一种纹理类型——<strong>渲染纹理（Render Texture）</strong></li><li>Unity中有两种方式使用渲染纹理：</li></ul><ol><li>在Project目录下创建一个渲染纹理，把某个摄像机的渲染目标设置成该渲染纹理，这样摄像机的渲染结果会实时更新到渲染纹理中，而不会显示在屏幕上。</li><li>屏幕后处理时，使用GrabPass命令或OnRenderImage函数来获取当前屏幕图像，Unity会把这个屏幕图像放到一张和屏幕分辨率等同的渲染纹理中，之后我们可以在自定义的Pass中把它们当做普通的纹理来处理，从而实现各种屏幕特效。</li></ol><h3 id="玻璃效果"><a href="#玻璃效果" class="headerlink" title="玻璃效果"></a>玻璃效果</h3><ul><li>Unity shader中我们可以使用一种特殊的Pass来完成获取屏幕图像的目的，这就是GrabPass。</li><li>在shader中定义一个GrabPass后，Unity会把当前屏幕的截图保存在一张纹理中，我们可以再之后的Pass中访问它。</li><li>使用GrabPass时，需要额外小心<strong>物体的渲染队列设置</strong>。</li><li>我们需要把物体的渲染队列设置为透明队列（”Queue” &#x3D; “Tansparent”）。</li></ul><h2 id="程序纹理"><a href="#程序纹理" class="headerlink" title="程序纹理"></a>程序纹理</h2><ul><li>指的是由计算机生成的图像。</li><li>好处在于可以使用各种参数来控制纹理的外观。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第九章-更复杂的光照</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E4%B9%9D%E7%AB%A0-%E6%9B%B4%E5%A4%8D%E6%9D%82%E7%9A%84%E5%85%89%E7%85%A7/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E4%B9%9D%E7%AB%A0-%E6%9B%B4%E5%A4%8D%E6%9D%82%E7%9A%84%E5%85%89%E7%85%A7/</url>
    
    <content type="html"><![CDATA[<h2 id="Unity的渲染路径"><a href="#Unity的渲染路径" class="headerlink" title="Unity的渲染路径"></a>Unity的渲染路径</h2><ul><li>在Unity里，<strong>渲染路径</strong>决定了光照是如何应用到Unity Shader中的。因此如果想要处理光照，我们需要为每个Pass指定它使用的渲染路径，然后Unity就会将光源和处理后的信息放在数据里，我们才可以访问</li><li>Unity支持多种渲染路径，在Unity5.0之前有：<strong>前向渲染路径（Forward Rendering Path）、延迟渲染路径（Deferred Rendering Path）</strong> 和<strong>顶点照明渲染路径（Vertex Rendering Path）</strong>。但在Unity5.0之后，顶点照明渲染路径已经被Unity抛弃（但是仍然对之前使用了顶点照明渲染路径的Unity Shader兼容），新的延迟渲染路径代替了原来的延迟渲染路径（也对之前的版本兼容）。</li><li>大多数情况下，一个项目只使用一种渲染路径，因此我们可以为整个项目设置渲染时的渲染路径。<br>Edit-&gt;Project Setting-&gt;Player-&gt;Other Setting-&gt;Rendering Path<br>默认情况下，该设置选择的是前向渲染路径。</li><li>但有时我们希望可以使用多个渲染路径，例如摄像机A使用前向渲染路径，摄像机B使用延迟渲染路径。这时我们可以在摄像机设置中选择渲染路径以覆盖Project Setting中的设置。<br>如果选择Use Player Settings，那么这个摄像机就会使用Project Setting中的设置；否则就会覆盖。注意如果当前显卡不支持选择的渲染路径，Unity就会自动选择更低一级的渲染路径。<br>我们可以在Pass中使用标签来指定该Pass使用的渲染路径。这是通过设置Pass的<strong>LightMode</strong>标签实现的。<h4 id="LightMode标签支持的渲染路径设置选项"><a href="#LightMode标签支持的渲染路径设置选项" class="headerlink" title="LightMode标签支持的渲染路径设置选项"></a>LightMode标签支持的渲染路径设置选项</h4></li></ul><table><thead><tr><th>标签名</th><th>描述</th></tr></thead><tbody><tr><td>Always</td><td>不管使用哪种渲染路径，该Pass总会被渲染，但不会计算然和光照。</td></tr><tr><td>ForwardBase</td><td>用于<strong>前向渲染</strong>。该Pass会计算环境光、最重要的平行光、逐顶点&#x2F;SH光源和Lightmaps</td></tr><tr><td>ForwardAdd</td><td>用于<strong>前向渲染</strong>。该Pass会计算额外的逐像素光源，每个Pass对应一个光源</td></tr><tr><td>Deferred</td><td>用于<strong>延迟渲染</strong>。该Pass会渲染G缓冲(G-buffer)</td></tr><tr><td>ShadowCaster</td><td>把物体的深度信息渲染到阴影映射纹理（shadowmap）或一张深度纹理中。</td></tr><tr><td>PrepassBase</td><td>用于<strong>遗留的延迟渲染</strong>。该Pass会渲染法线和高光反射的指数部分</td></tr><tr><td>PrepassFinal</td><td>用于<strong>遗留的延迟渲染</strong>。该Pass通过合并纹理、光照和自发光来渲染得到最后的颜色</td></tr><tr><td>Vertex、VertexLMRGBM 和 VertexLM</td><td>用于<strong>遗留的顶点照明渲染</strong></td></tr></tbody></table><p>如果我们没有指定任何渲染路径，那么一些光照就不会被正确赋值，我们计算出的效果也就有可能是错误的。</p><h3 id="前向渲染路径"><a href="#前向渲染路径" class="headerlink" title="前向渲染路径"></a>前向渲染路径</h3><ol><li>前向渲染的原理</li></ol><ul><li>每进行一次完整的前向渲染，我们需要渲染该对象的渲染图元，并计算两个缓冲区的信息：一个是颜色缓冲区，一个是深度缓冲区。我们利用深度缓冲来决定一个片元是否可见，如果可见就更新颜色缓冲区中的颜色值。</li><li>对于每个逐像素光源，我们都需要进行一次完整的渲染流程。如果一个物体在多个逐像素光源的影响区域内，那么就需要执行多个Pass，每个Pass计算一个逐像素光源的光照结果，然后在帧缓冲中把这些光照混合起来得到最终的颜色值。假设，场景中有N个物体，每个物体受到M个光源影响，那么渲染整个场景需要N*M个Pass。可以看出有大量逐像素光照，那么需要执行的Pass数目也会很大。因此，渲染引擎通常会限制每个物体的逐像素光照数目。</li></ul><ol start="2"><li>Unity中的前向渲染</li></ol><ul><li>事实上，一个Pass不仅仅可以用来计算逐像素光照，这取决于光照计算所处流水线阶段，以及计算时使用的数学模型。</li><li>在Unity中，前向渲染路径有3种处理光照（即照亮物体）的方式：<strong>逐顶点处理</strong>、<strong>逐像素处理</strong>、<strong>球谐函数（Spherical Harmonics，SH）处理</strong>。决定一个光源使用哪种处理模式取决于它的类型和渲染模式。光源类型指的是该光源是平行光还是其他类型的光源。而光源的渲染模式指的是该光源是否是<strong>重要的</strong>（Important）。如果我们把光照的模式设置为Important，意味着我们告诉Unity，希望Unity把这个光源当做逐像素光源处理。我们可以在光源的Light组件中设置这些属性。</li><li>在前向渲染中，Unity会根据场景中各个光源的设置以及光源对物体的影响程度（例如，距离物体的远近、光源强度等）对这些光源进行重要度排序。其中一部分光源会按照逐像素处理，然后最多4个光源按照逐顶点的方式处理，剩下的光源可以按SH方式处理。<h4 id="Unity使用的判断规则如下："><a href="#Unity使用的判断规则如下：" class="headerlink" title="Unity使用的判断规则如下："></a>Unity使用的判断规则如下：</h4></li><li>场景中最亮的平行光总是按照逐像素处理的。</li><li>渲染模式被设置为Not Important的光源，会按照逐顶点或者SH处理。</li><li>渲染模式被设置为Important的光源，会按逐像素处理。</li><li>如果根据以上规则得到的逐像素光源数量小于Quality Setting中的逐像素光源数量（Pixel Light Count），会有更多的光源以逐像素的方式进行渲染。</li></ul><h4 id="我们在Pass中进行光照计算"><a href="#我们在Pass中进行光照计算" class="headerlink" title="我们在Pass中进行光照计算"></a>我们在Pass中进行光照计算</h4><ul><li>前向渲染有两种Pass：Base Pass和Additional Pass。</li><li>Base Pass 设置：<figure class="highlight arduino"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-comment">//渲染设置</span><br>Tags &#123; <span class="hljs-string">&quot;LightMode&quot;</span> = <span class="hljs-string">&quot;ForwardBase&quot;</span> &#125;<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> multi_compile_fwdbase</span><br></code></pre></td></tr></table></figure></li></ul><p>光照计算:<br>一个逐像素的平行光以及所有逐顶点和SH光源</p><ul><li>Addtional Pass 设置：<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-comment">//渲染设置</span><br>Tags&#123; <span class="hljs-string">&quot;LightMode&quot;</span> = <span class="hljs-string">&quot;ForwardAdd&quot;</span> &#125;<br>Blend One One<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> multi_compile_fwdadd</span><br></code></pre></td></tr></table></figure></li></ul><p>光照计算:<br>其他影响该物体的逐像素光源，每个光源执行一次Pass</p><ul><li>Base Pass中渲染的平行光默认是支持阴影的，而Additional Pass 中渲染的光源在默认情况下是没有阴影效果的。但是可以在Additional Pass中使用 #pragma multi_compile_fwdadd_fullshadows代替#pragma multi_compile_fwdadd编译指令，为点光源和聚光灯开启阴影效果，但这需要Unity内部使用更多的Shader变种。</li><li>环境光和自发光都在Base Pass中计算，因为这两种光照通常只需要计算一次。</li><li>在Additional Pass 的渲染中，开启了混合，这是为了与上一次的光照结果在帧缓存中进行叠加。</li><li>前向渲染中，一个Unity Shader通常会定义一个Base Pass(也可以定义多次，例如双面渲染时)，以及一个Additional Pass。一个Base Pass仅会执行一次，而一个Additional Pass会根据影响该物体的其他逐像素光源的数目被多次调用。</li><li>这里给出的光照计算是<strong>通常情况</strong>下我们在每种Pass中进行的计算。实际上，渲染路径的设置用于告诉Unity该Pass在前向渲染中的位置，然后渲染引擎进行相关的计算并填充一些内置变量，如何使用这些变量完全取决于开发者的选择。</li></ul><ol start="3"><li>内置的光照变量和函数</li></ol><h4 id="前向渲染可以使用的内置光照变量"><a href="#前向渲染可以使用的内置光照变量" class="headerlink" title="前向渲染可以使用的内置光照变量"></a>前向渲染可以使用的内置光照变量</h4><table><thead><tr><th>名称</th><th>类型</th><th>描述</th></tr></thead><tbody><tr><td>_LightColor0</td><td>float4</td><td>该Pass处理的逐像素光源的颜色</td></tr><tr><td>_WorldSpaceLightPos0</td><td>float4</td><td>_WorldSpaceLightPos0.xyz,是该Pass处理的逐像素光源的位置。如果该光源是平行光，那么_WorldSPaceLightPos.w是0，其他光源类型是1</td></tr><tr><td>_LightMatrix0</td><td>float4X4</td><td>从世界空间到光源空间的变换矩阵。可以用于采样cookie和光强衰减（attenuation）纹理</td></tr><tr><td>unity_4LightPosX0,unity_4LightPosY0,unity_4LightPosZ0</td><td>float4</td><td>仅用于Base Pass。前4个非重要点光源在世界空间中的位置。</td></tr><tr><td>unity_4LightAtten0</td><td>float4</td><td>仅用于Base Pass。存储了前4个非重要点光源你的衰减因子。</td></tr><tr><td>unity_LightColor</td><td>half4[4]</td><td>仅用于Base Pass。存储了前4个非重要的点光源的颜色。</td></tr></tbody></table><h4 id="前向渲染可以使用的内置光照函数"><a href="#前向渲染可以使用的内置光照函数" class="headerlink" title="前向渲染可以使用的内置光照函数"></a>前向渲染可以使用的内置光照函数</h4><ul><li>为了完整性，我们再次列出前向渲染中可以使用的内置光照函数。</li></ul><table><thead><tr><th>函数名</th><th>描述</th></tr></thead><tbody><tr><td>float3 WorldSpaceLightDir(float4 v)</td><td><strong>仅可用于前向渲染</strong>。输入一个模型空间中的顶点位置，返回世界空间中从该点到光源的光照方向。内部实现使用了UnityWorldSpaceLightDir函数。没有被归一化。</td></tr><tr><td>float3 UnityWorldSpaceLightDir(float4 v)</td><td><strong>仅可用于前向渲染</strong>。输入一个世界空间中的顶点位置，返回世界空间中从该点到光源的光照方向。</td></tr><tr><td>float3 ObjSpaceLightDir(float4 v)</td><td><strong>仅可用于前向渲染中</strong>。输入一个模型空间中的顶点位置，返回模型空间中从该点到光源的光照方向</td></tr><tr><td>float3 Shade4PointLights(…)</td><td><strong>仅可用于前向渲染中</strong>。计算四个点光源的光照，它的参数是已经打包进矢量的光照数据，通常就是上表中的内置变量。前向渲染通常会使用这个函数来计算逐顶点光照。</td></tr></tbody></table><p>这里给出的变量和函数并不完整。之后用到不在表中的变量和函数会特别说明。</p><h3 id="顶点照明渲染路径"><a href="#顶点照明渲染路径" class="headerlink" title="顶点照明渲染路径"></a>顶点照明渲染路径</h3><ul><li>顶点照明渲染路径是对硬件配置要求最少、运算性能最高，但同时也是得到的效果最差的一种类型，它不支持那些逐像素才能得到的效果，例如阴影、法线映射、高精度的光照反射等。它仅仅是前向渲染的一个子集，也就是说所有可以在顶点照明渲染路径中实现的功能都可以在前向渲染路径中完成。就如它的名字一样，顶点照明渲染路径只是使用了逐顶点的方式来计算光照。如果使用顶点照明渲染路径，那么Unity只会填充那些逐顶点相关的光源变量，意味着我们不可以使用一些逐像素光照变量。</li></ul><ol><li>Unity中的顶点照明渲染</li></ol><ul><li>顶点照明渲染通常在一个Pass中就可以完成对物体的渲染。在这个Pass中，我们会计算我们关心的所有光源对该物体的照明，并且这个计算时逐顶点处理的。这是Unity中最快速的渲染路径，并且具有最广泛的硬件支持。</li></ul><ol start="2"><li>可访问的内置变量和函数</li></ol><ul><li>在Unity中，我们可以在一个顶点照明的Pass中最多访问到8个逐顶点光源。如果影响该物体的光源数目小于8个，那么数组中剩下的光源颜色会被设置成黑色。<h4 id="顶点照明渲染路径中可以使用的内置变量"><a href="#顶点照明渲染路径中可以使用的内置变量" class="headerlink" title="顶点照明渲染路径中可以使用的内置变量"></a>顶点照明渲染路径中可以使用的内置变量</h4></li></ul><table><thead><tr><th>名称</th><th>类型</th><th>描述</th></tr></thead><tbody><tr><td>unity_LightColor</td><td>half4[8]</td><td>光源颜色</td></tr><tr><td>Unity_LightPosition</td><td>float4[8]</td><td>xyz分量是视角空间中的光源位置。如果光源是平行光，w分量为0，其他光源类型z分量值为1。</td></tr><tr><td>unity_LightAtten</td><td>half4[8]</td><td>光源衰减因子。如果光源是聚光灯，x分量是cos(spotAngle&#x2F;2)，y分量是1&#x2F;cos(spotAngle&#x2F;4)；如果是其他类型的光源，x分量是-1，y分量是1。z分量是衰减的平方，w分量是光源范围开根号的结果。</td></tr><tr><td>unity_SpotDirection</td><td>float4[8]</td><td>如果光源是聚光灯的话，值为视角空间的聚光灯位置；如果是其他类型的光源，值为(0,0,1,0)</td></tr></tbody></table><h4 id="顶点照明渲染路径中可以使用的内置函数"><a href="#顶点照明渲染路径中可以使用的内置函数" class="headerlink" title="顶点照明渲染路径中可以使用的内置函数"></a>顶点照明渲染路径中可以使用的内置函数</h4><table><thead><tr><th>函数名</th><th>描述</th></tr></thead><tbody><tr><td>float3 ShadeVertexLights(float4 vertex,float3 normal)</td><td>输入模型空间中的顶点位置和法线，计算四个逐顶点光源的光照以及环境光。内部实现实际上调用了ShadeVertexLightsFull函数</td></tr><tr><td>float3 ShadeVertexLightsFull(float4 vertex,float3 normal,int lightCount,bool spotLight)</td><td>输入模型空间中的顶点位置和法线，计算lightCount个光源的光照以及环境光。如果spotLight值为true，那么这些光源会被当成聚光灯来处理，虽然结果更加精确，但计算更加耗时；否则，按点光源处理。</td></tr></tbody></table><h3 id="延迟渲染路径"><a href="#延迟渲染路径" class="headerlink" title="延迟渲染路径"></a>延迟渲染路径</h3><ul><li>前向渲染在有大量实时光源时，性能会急剧下降。</li><li>除了颜色缓冲和深度缓冲之外，延迟渲染还会使用新的缓冲区，这些缓冲区被统称为G缓冲(G-buffer)，其中G是英文的Geometry的缩写。G缓冲区保存了我们所关心的表面（通常指离摄像机最近的表面）的其他信息。例如表面的法线、位置、用于光照计算的材质属性。</li></ul><ol><li>延迟渲染的原理</li></ol><ul><li>延迟渲染使用两个Pass。</li><li>第一个Pass仅计算哪些片元可见，通常使用深度缓冲来计算。当片元可见时，就把相关信息存储到G缓冲区中。</li><li>第二个Pass中利用G缓冲区的各个片元信息进行真正的光照计算。</li></ul><ol start="2"><li>Unity中的延迟渲染</li></ol><ul><li>Unity中有两种延迟渲染路径，一种是Unity5之前遗留的延迟渲染路径，一种是Unity5.x中使用的延迟渲染路径。游戏中使用大量光照时，我们希望尽可能使用延迟渲染路径，但这种路径需要一定的硬件支持。</li><li>对于延迟渲染路径，它最适合在场景中光源数目很多、如果使用前向渲染会造成性能瓶颈的情况下使用。而且，延迟渲染路径中每个光源都可以逐像素的方式处理。</li><li>一些缺点：<br>不支持真正的抗锯齿<br>不能处理半透明物体<br>对显卡有一定要求。显卡必须支持MRT（Multiple Render Targets）、Shader3.0及以上、深度渲染纹理以及双面的模板缓冲。</li><li>对于每个物体来说，第一个Pass只会执行一次</li><li>第二个Pass用于计算真正的光照模型。</li><li>默认的G缓冲区包含了以下几个渲染纹理：（注意Unity版本不同可能储存内容会不同）<br>RT0：格式是ARGB32，RGB通道用于存储漫反射颜色，A通道没有被使用。<br>RT1：格式是ARGB32，RGB通道用于存储高光反射颜色，A通道用于存储高光反射的指数部分。<br>RT2：格式是ARGB2101010，RGB通道用于存储法线，A通道没有被使用。<br>RT3：格式是ARGB32（非HDR）或ARGBHalf（HDR），用于存储自发光+lightmap+反射探针。<br>深度缓冲和模板缓冲。<br>在第二个Pass中计算光照时，默认情况下只可以使用Unity内置的Standard光照模型。</li></ul><ol start="3"><li>可访问的内置变量和函数<h4 id="延迟渲染路径中可以使用的内置变量"><a href="#延迟渲染路径中可以使用的内置变量" class="headerlink" title="延迟渲染路径中可以使用的内置变量"></a>延迟渲染路径中可以使用的内置变量</h4>名称 | 类型 | 描述</li></ol><p>— | — | —<br>_LightColor | float4 | 光源颜色<br>_LightMatrix0 | float4x4 | 从世界空间到光源空间的变换矩阵。可以用于采样cookie和光强衰减纹理。</p><h2 id="Unity的光源类型"><a href="#Unity的光源类型" class="headerlink" title="Unity的光源类型"></a>Unity的光源类型</h2><ul><li>Unity一共支持4种光源类型：平行光、点光源、聚光灯和面光源(area Light)。面光源仅在烘焙时才可发挥作用。<h3 id="光源类型有什么影响"><a href="#光源类型有什么影响" class="headerlink" title="光源类型有什么影响"></a>光源类型有什么影响</h3></li><li>Shader中最常使用的光源属性有光源的<strong>位置</strong>、<strong>方向</strong>（准确的说是到达某点的方向）、<strong>颜色</strong>、<strong>强度以及衰减</strong>（具体的说就是，到某点的衰减与该点到光源的距离有关）这5个属性。这些属性和它们的几何定义息息相关。</li></ul><ol><li>平行光</li></ol><ul><li>照亮范围没有限制。</li><li>没有唯一的位置。</li><li>它的几何属性只有方向，并且到所有点的方向都是一样的。</li><li>没有衰减，光到任何一点的强度都是一样的。</li></ul><ol start="2"><li>点光源</li></ol><ul><li>点光源的照亮空间有限，它是由空间中的一个球体定义的。</li><li>可以表示从一个点发出的、向所有方向延伸的光。</li><li>球体半径可以修改Range属性来调整。</li><li>点光源有位置属性</li><li>方向属性需要用光源位置减去某点的位置来得到它到该点的方向</li><li>点光源的颜色和强度可以再Light组件面板中调整。</li><li>点光源是会衰减的。</li></ul><ol start="3"><li>聚光灯</li></ol><ul><li>照亮空间由一块锥形区域定义。</li><li>锥形区域的半径由面板中的Range属性决定，锥形的张开角度由Spot Angle属性决定</li><li>有位置属性</li><li>方向属性需要用光源位置减去某点的位置来得到它到该点的方向</li><li>聚光灯也会衰减<h2 id="Unity的光照衰减"><a href="#Unity的光照衰减" class="headerlink" title="Unity的光照衰减"></a>Unity的光照衰减</h2></li></ul><p><strong>纹理查找采样的弊端：</strong></p><ul><li>需要预处理来得到采样纹理，而且纹理的大小也会影响衰减的精度。</li><li>不直观，同时也不方便，一旦把数据存储到查找表中，我们就无法使用其他数学公式来计算衰减。<h3 id="用于光照衰减的纹理"><a href="#用于光照衰减的纹理" class="headerlink" title="用于光照衰减的纹理"></a>用于光照衰减的纹理</h3></li><li>我们通常只关心_LightTexture0对角线上的纹理颜色，这些值表明了在光源空间中不同位置的点的衰减值。</li><li>首先使用世界空间到光源空间的变换矩阵_LightMatrix0，将坐标转换到光源空间。</li><li>使用顶点距离的平方在纹理中采样，使用UNITY_ATTEN_CHANNEL取衰减值所在的分量。</li></ul><h3 id="使用数学公式计算衰减"><a href="#使用数学公式计算衰减" class="headerlink" title="使用数学公式计算衰减"></a>使用数学公式计算衰减</h3><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs abnf">float distance <span class="hljs-operator">=</span> length(_WorldSpaceLightPos0.xyz - i.worldPosition.xyz)<span class="hljs-comment">;</span><br><span class="hljs-attribute">atten</span> <span class="hljs-operator">=</span> <span class="hljs-number">1.0</span>/distance<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><p>但我们无法通过内置变量得到光源范围、聚光灯朝向、张开角度等信息，因此得到的效果有些差强人意。</p><h2 id="Unity的阴影"><a href="#Unity的阴影" class="headerlink" title="Unity的阴影"></a>Unity的阴影</h2><h3 id="阴影如何实现"><a href="#阴影如何实现" class="headerlink" title="阴影如何实现"></a>阴影如何实现</h3><ul><li>阴影区域的产生是应为光线无法到达这些区域。</li><li>实时渲染中使用Shadow Map技术，将摄像机与光源位置重叠，看不到的地方就是光源无法到达的地方。</li><li>前向渲染中，场景中最重要的平行光开启阴影的话，Unity会为该光源计算它的<strong>阴影映射纹理</strong>(shadowmap)。记录从光源位置出发能看到的场景中距离最近的表面位置（深度信息）。</li><li>Unity使用一个额外的Pass，LightMode标签设置为<strong>ShadowCaster</strong>。这个Pass渲染目标是阴影映射纹理。</li><li>开启光源阴影效果后会寻找标签为ShadowCaster的Pass，没有找到就在Fallback指定的UnityShader中继续寻找，仍未找到的话，这个光源就无法透射阴影。找到响应Pass后就会使用这个Pass更新Shadowmap。</li><li>Unity中使用<strong>屏幕空间的阴影映射技术（Screenspace Shadow Map）</strong>，显卡支持MRT才可以使用这个技术。</li><li>使用透明度测试的材质需要在ShadowCaster中也进行了透明度测试，通常在Fallback中设置”Transform&#x2F;Cutoff&#x2F;VertexLit”来使用unity内部提供的透明度测试可用的shadowCaster。- 使用透明度混合的材质通常不可以投射和接受阴影，因为关闭深度写入会影响shadowmap的生成，通常在Fallback设置”Transform&#x2F;VertexLit”，但可以用”VertexLit”来代替它，从而将物体作为非透明物体的形式投射和接收阴影。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第八章-透明效果</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%85%AB%E7%AB%A0-%E9%80%8F%E6%98%8E%E6%95%88%E6%9E%9C/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%85%AB%E7%AB%A0-%E9%80%8F%E6%98%8E%E6%95%88%E6%9E%9C/</url>
    
    <content type="html"><![CDATA[<ul><li>实时渲染中要实现透明效果，通常在渲染模型时控制他的透明通道。</li><li>Unity中有两种方式实现透明效果：一种是<strong>透明度测试</strong>这种方法无法得到真正的半透明效果；另一种是<strong>透明度混合</strong>。</li><li>之前没有强调过渲染顺序的问题，因为深度缓冲的存在。在实时渲染中，深度缓冲是用于解决可见性的，他可以决定那些部分物体会被渲染在前面，而哪些部分会被其他物体遮挡。它的基本思想是：根据深度缓冲中的值来判断该片元距离摄像机的距离，当渲染一个片元时，需要把它的深度值和已经存在于深度缓冲中的值进行比较（如果开启了深度测试），如果它的值距离摄像机更远，那么说明这个物体不该被渲染到屏幕上（有物体遮挡了它）；否则这个片元应该覆盖此时颜色缓冲中的像素值，并且把它的深度值更新到深度缓存中（如果开启了深度写入）。<h3 id="透明度测试"><a href="#透明度测试" class="headerlink" title="透明度测试"></a>透明度测试</h3>只要一个片元的透明度不满足条件（通常是小于某个阈值）,那么它对应的片元就会被舍弃。被舍弃的片元就不会进行任何处理，也不会对颜色缓冲造成任何影响；否则，就会按照不透明物体来处理它，即进行深度测试、深度写入等。透明度测试是不用关闭深度写入的，它和其他不透明物体最大的不同就是它会根据透明度来舍弃一些片元。虽然简单，但是产生的效果也很极端，要么完全透明，要么完全不透明。<h3 id="透明度混合"><a href="#透明度混合" class="headerlink" title="透明度混合"></a>透明度混合</h3>使用当前片元的透明度作为混合因子，与已经储存在颜色缓冲区中的颜色值进行混合，得到新的颜色。但是透明度混合需要关闭深度写入，这使得我们需要非常小心物体的渲染顺序。需要注意的是，透明度混合只关闭了深度写入，并没有关闭深度测试。这意味着，当使用透明度混合渲染一个片元时，还是会和深度缓冲区的值进行比较，如果他的深度值距离相机更远，那么就不会进行混合操作。也就是对于透明度混合来说，深度缓冲是只读的。</li></ul><h2 id="为什么渲染顺序很重要"><a href="#为什么渲染顺序很重要" class="headerlink" title="为什么渲染顺序很重要"></a>为什么渲染顺序很重要</h2><p>渲染透明物体如果不关闭深度写入，那么在一个透明物体后面的物体便不会被渲染，即相当于被透明物体遮挡了，这并不符合逻辑。但是关闭了深度写入，这就破坏了深度缓冲的工作机制，即使这是必要的。</p><ul><li>我们先来看最简单的情况，假设场景中存在两个物体A和B，A是半透明物体，B是不透明物体，B处于A后方。</li><li>第一种情况是先渲染B再渲染A。不透明物体开启了深度测试和写入，此时深度缓冲去没有数据，B写入深度和颜色缓冲区。随后我们渲染A，透明物体会进行深度测试，因此法线A距离摄像机更近，因此，我们会使用A的透明度与颜色缓冲区中的颜色进行混合，得到正确的半透明效果。</li><li>第二种情况，我们先渲染A，再渲染B。渲染A时，深度缓冲区中没有任何数据，因此A直接写入颜色缓冲区。随后我们渲染B，渲染时B进行深度测试，深度缓冲区中依然没有数据，B直接写入并覆盖A在颜色缓冲区的数据，导致了实际效果仿佛是B遮挡了A，然而这时错误的。<br>基于这种情况，渲染引擎一般都会先对物体进行排序，再渲染。常用方法是：</li><li>先渲染所有不透明物体，并且开启它们的深度测试和写入。</li><li>把半透明物体按照它们距离摄像机的远近进行排序，然后按照从后往前的顺序渲染这些半透明物体，并开启它们的深度测试，但关闭深度写入。</li><li>但这样仍然存在一些问题，我们的深度值记录的是一个像素的深度，并不是一个物体的深度，如果几个物体循环重叠，这样就会出现问题。<br><img src="https://img-blog.csdnimg.cn/20190417231355150.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDg2NjM5,size_16,color_FFFFFF,t_70" alt="循环重叠"></li></ul><h2 id="Unity-Shader-的渲染顺序"><a href="#Unity-Shader-的渲染顺序" class="headerlink" title="Unity Shader 的渲染顺序"></a>Unity Shader 的渲染顺序</h2><ul><li>Unity 为了解决渲染顺序的问题提供了<strong>渲染队列</strong>这一解决方案。我们可以使用SubShader的Queue标签来决定我们的模型将归于哪个渲染队列。Unity在内部 使用一系列整数索引来表示每个渲染队列，且索引号越小表示越早被渲染。</li><li>Unity 中提前定义了5个渲染队列，且索引号越小表示越早被渲染。在Unity5中，Unity提前定义了5个渲染队列，在每个队列中间我们也可以使用其他队列。</li></ul><table><thead><tr><th>名称</th><th>队列索引号</th><th>描述</th></tr></thead><tbody><tr><td>Background</td><td>1000</td><td>这个渲染队列会在任何其他渲染队列之前被渲染，我们通常使用该队列来渲染那些需要绘制在背景上的物体。</td></tr><tr><td>Geometry</td><td>2000</td><td>默认的渲染队列，大多数物体都使用这个队列。不透明物体使用这个队列</td></tr><tr><td>AlphaTest</td><td>2450</td><td>需要透明度测试的物体使用这个队列。在Unity5中它从Geometry队列中被单独分出来，这是因为在所有不透明物体渲染之后再渲染它会更加高效。</td></tr><tr><td>Transparent</td><td>3000</td><td>这个队列中的物体会在所有Geometry和AlphaTest物体渲染后，再<strong>从后往前</strong>的顺序进行渲染。任何使用了透明度混合（例如关闭了深度写入的Shader）的物体都应该使用该队列</td></tr><tr><td>Overlay</td><td>4000</td><td>该队列用于实现一些叠加效果。任何需要在最后渲染的物体都应该使用该队列。</td></tr></tbody></table><h2 id="透明度混合-1"><a href="#透明度混合-1" class="headerlink" title="透明度混合"></a>透明度混合</h2><ul><li>它会使用当前片元的透明度作为混合因子，与已经储存在颜色缓冲区中的颜色值进行混合，得到新的颜色。透明度混合需要关闭深度写入，我们要非常小心物体的渲染顺序。</li><li>为了进行混合，我们需要使用Unity提供的混合命令——Blend。要实现半透明效果，就需要把当前自身的颜色和已经存在于颜色缓冲中的颜色进行混合，混合时使用的函数就是由该指令决定的。</li></ul><h4 id="ShaderLab的Blend命令"><a href="#ShaderLab的Blend命令" class="headerlink" title="ShaderLab的Blend命令"></a>ShaderLab的Blend命令</h4><table><thead><tr><th>语义</th><th>描述</th></tr></thead><tbody><tr><td>Blend Off</td><td>关闭混合</td></tr><tr><td>Blend SrcFactor DstFactor</td><td>开启混合，并设置混合因子。源颜色（该片元产生的颜色）会乘以SrcFactor，而目标颜色（已经存在于颜色缓存的颜色）会乘以DstFactor，然后把两者相加后再存入颜色缓冲中</td></tr><tr><td>Blend SrcFactor DstFactor，SrcFactorA DstFactorA</td><td>和上面几乎一样，只是使用不同的因子来混合透明通道</td></tr><tr><td>BlendOp BlendOperation</td><td>并非是把源颜色和目标颜色简单相加后混合，而是使用BlendOperation对它们进行其他操作</td></tr></tbody></table><p>只有打开混合模式以后，设置片元的透明通道才有意义，Unity在我们使用Blend命令的时候就自动帮我们打开了。我们通常会把源颜色的混合因子SrcFactor设为SrcAlpha，而目标颜色的混合因子DstFactor设为OneMinusSrcAlpha。这意味着，经过混合后的新颜色是：<br><img src="https://img-blog.csdnimg.cn/20190420232324240.png" alt="透明度混合公式">  </p><h2 id="开启深度写入的半透明效果"><a href="#开启深度写入的半透明效果" class="headerlink" title="开启深度写入的半透明效果"></a>开启深度写入的半透明效果</h2><ul><li>之前我们解释了由于关闭深度写入带来的各种问题。当模型本身有复杂的遮挡关系或是包含了复杂的非凸网格的时候，就会有各种各样因为排序错误产生的错误的透明效果。由于关闭了深度写入我们无法对模型进行像素级别的深度排序。这时我们可以想办法重新利用深度写入，让模型可以像半透明物体一样进行淡入淡出。  </li><li>一种解决方法是<strong>使用两个Pass</strong>来渲染模型：第一个Pass开启深度写入，但不输出颜色，它的目的仅仅是为了把该模型的深度值写入深度缓冲中；第二个Pass进行正常的透明度混合，由于上一个Pass已经得到了逐像素的正确的深度信息，该Pass就可以按照像素级别的正确深度信息，但这种方法的缺点在于多使用一个Pass造成的性能影响。</li></ul><h2 id="ShaderLab-的混合命令"><a href="#ShaderLab-的混合命令" class="headerlink" title="ShaderLab 的混合命令"></a>ShaderLab 的混合命令</h2><ul><li>首先我们看一下混合是怎样实现的。当片元着色器产生一个颜色时，可以选择与颜色缓存中的颜色进行混合。这样混合就和两个操作数有关：<strong>源颜色</strong>和<strong>目标颜色</strong>有关。源颜色我们使用S表示，指的是片元着色器产生的颜色；目标颜色我们使用D表示，指的是从颜色缓冲中读取到的颜色值。对它们混合后得到的颜色值，我们用O表示它会重新写入到颜色缓冲中。需要注意的是，当我们谈及混合中的源颜色、目标颜色和输出颜色时，它们都包含了RGBA四个通道的颜色值，而并非仅仅是RGB通道。</li><li>想要使用混合，我们必须开启它。在Unity中，当我们使用Blend（Blend Off命令除外），除了设置混合状态也会自动开启混合。在其他图形API中我们是需要手动开启的。例如在OpenGL中，我们需要使用glEnable(GL_BLEND)来开启混合。但在Unity中吗，它已经在背后为我们做了这些工作。</li></ul><h3 id="混合等式和参数"><a href="#混合等式和参数" class="headerlink" title="混合等式和参数"></a>混合等式和参数</h3><ul><li>混合是一个逐片元级的操作，而且它是不可编程的，但是确实高度可配置的。我们可以控制混合时使用的运算操作、混合因子等来影响混合。</li><li>现在我们知道两个操作数：源颜色S和目标颜色D，想要得到输出颜色O就必须使用一个等式来计算。我们把这个等式称作<strong>混合等式</strong>。当进行混合时，我们需要使用两个混合等式:一个用于混合RGB通道，一个用于混合A通道。设置混合状态时，我们就相当于设置了混合等式中的<strong>操作</strong>和<strong>因子</strong>。默认情况下，混合等式使用的操作符是加操作（也可以设置其他操作），我们只需要设置一下混合因子就可以了。由于需要两个等式，每个等式需要两个因子，所以我们总共需要4个因子。<h4 id="ShaderLab中设置混合因子的命令"><a href="#ShaderLab中设置混合因子的命令" class="headerlink" title="ShaderLab中设置混合因子的命令"></a>ShaderLab中设置混合因子的命令</h4>命令 | 描述</li></ul><p>—|—<br>Blend SrcFactor DstFactor| 开启混合，并设置混合因子。源颜色（该片元产生的颜色）会乘以SrcFactor，而目标颜色（已经存在于颜色缓存的颜色）会乘以DstFactor，然后把两者相加后再存入颜色缓冲中<br>Blend SrcFactor DstFactor,SrcFactorA DstFactorA | 和上面一样，只是使用不同的因子来混合透明通道</p><ul><li>第一个命令只提供两个因子，这意味着将使用同样的混合因子来混合RGB通道和A通道。</li><li>混合公式<br><img src="https://img-blog.csdnimg.cn/20190421230847604.png" alt="透明度加法混合公式"></li></ul><h4 id="ShaderLab中的混合因子"><a href="#ShaderLab中的混合因子" class="headerlink" title="ShaderLab中的混合因子"></a>ShaderLab中的混合因子</h4><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>One</td><td>因子为1</td></tr><tr><td>Zero</td><td>因子为0</td></tr><tr><td>SrcColor</td><td>因子为源颜色值。当用于RGB的混合等式时，使用SrcColor中的RGB分量作为混合因子；当用于混合A的混合公式时，使用SrcColor的A分量作为混合因子</td></tr><tr><td>SrcAlpha</td><td>因子为源颜色的透明度值（A通道）</td></tr><tr><td>DstColor</td><td>因子为目标颜色值。当用于RGB的混合等式时，使用DstColor中的RGB分量作为混合因子；当用于混合A的混合公式时，使用DstColor的A分量作为混合因子</td></tr><tr><td>DstAlpha</td><td>因子为目标颜色的透明度值（A通道）</td></tr><tr><td>OneMinusSrcColor</td><td>因子为(1-源颜色值)。当用于混合RGB的混合等式时，使用结果的RGB分量作为混合因子；当用于混合A的混合等式时，使用结果的A分量作为混合因子。</td></tr><tr><td>OneMinusSrcAlpha</td><td>因子为(1-源颜色透明度)</td></tr><tr><td>OneMinusDstColor</td><td>因子为(1-目标颜色)。当用于混合RGB的混合等式时，使用结果的RGB分量作为混合因子；当用于混合A的混合等式时，使用结果的A分量作为混合因子。</td></tr><tr><td>OneMinusDstAlpha</td><td>因子为(1-目标颜色透明度)</td></tr></tbody></table><h4 id="混合操作"><a href="#混合操作" class="headerlink" title="混合操作"></a>混合操作</h4><ul><li>我们可以使用ShaderLab的BlendOp BlendOperation 命令，即混合操作命令来设置混合操作的操作符。</li></ul><table><thead><tr><th>操作</th><th>描述</th></tr></thead><tbody><tr><td>Add</td><td>将混合后的源颜色和目的颜色相加。默认的混合操作。</td></tr><tr><td>Sub</td><td>用混合后的源颜色减去混合后目的颜色。</td></tr><tr><td>RevSub</td><td>用混合后的目的颜色减去混合后的源颜色。</td></tr><tr><td>Min</td><td>使用源颜色和目的颜色中较小的值，是逐分量比较的。</td></tr><tr><td>Max</td><td>使用源颜色和目的颜色中较大的值，是逐分量比较的。</td></tr></tbody></table><ul><li>混合操作命令通常是与混合因子命令一起工作的。但需要注意的是，当使用Min或Max混合操作时，混合因子是不起任何作用的。</li></ul><h3 id="常见的混合类型"><a href="#常见的混合类型" class="headerlink" title="常见的混合类型"></a>常见的混合类型</h3><ul><li>通过混合操作和混合因子命令的组合，我们可以得到一些类似Photoshop混合模式中的混合效果：<figure class="highlight awk"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></div></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">//</span>正常（Normal），即透明度混合<br>Blend SrcAlpha OneMinusSrcAlpha<br><br><span class="hljs-regexp">//</span>柔和相加（Soft Additive）<br>Blend OneMinusDstColor One<br><br><span class="hljs-regexp">//</span>正片叠底（Multiply），即相乘<br>Blend DstColor Zero<br><br><span class="hljs-regexp">//</span>两倍相乘（<span class="hljs-number">2</span>x Multiply）<br>Blend DstColor SrcColor<br><br><span class="hljs-regexp">//</span>变暗（Darken）<br>BlendOp Min<br>Blend One One<br><br><span class="hljs-regexp">//</span>变亮（Lighten）<br>BlendOp Max<br>Blend One One<br><br><span class="hljs-regexp">//</span>滤色（Screen）<br>Blend OneMinusDstColor One<br><span class="hljs-regexp">//</span>等同于<br>Blend One OneMinusSrcColor<br><br><span class="hljs-regexp">//</span>线性减淡<br>Blend One One<br></code></pre></td></tr></table></figure></li></ul><h2 id="双面渲染的透明效果"><a href="#双面渲染的透明效果" class="headerlink" title="双面渲染的透明效果"></a>双面渲染的透明效果</h2><ul><li>在现实生活中，如果一个物体是透明的，意味着我们不仅可以透过它看到其他物体的样子，也可以看到它内部的结构。之前的透明度混合或者是透明度测试中，我们都无法观察到正方体内部及其背面的形状，导致物体看起来就好像只有半个。这是因为默认情况下渲染引擎剔除了物体背面（相对于摄像机方向）的渲染图元。<h3 id="透明度测试的双面渲染"><a href="#透明度测试的双面渲染" class="headerlink" title="透明度测试的双面渲染"></a>透明度测试的双面渲染</h3></li><li>在Pass的渲染设置中添加Cull指令来关闭剔除即可（Cull Off）<h3 id="透明度混合的双面渲染"><a href="#透明度混合的双面渲染" class="headerlink" title="透明度混合的双面渲染"></a>透明度混合的双面渲染</h3></li><li>透明度混合的双面渲染要更复杂一些这是因为透明度混合需要关闭深度写入。对于透明度测试来说，由于我们没有关闭深度写入，因此可以利用深度缓冲逐像素的粒度进行深度排序，从而保证渲染的正确性。我们如果直接关闭剔除功能，我们无法保证同一个物体的正面和背面图元的渲染顺序，就可能的到错误的半透明效果。</li><li>为此，我们把双面渲染的工作分成两个Pass——第一个Pass只渲染背面，第二个Pass只渲染正面，由于Unity会顺序执行各个Pass，因此我们可以保证背面总是在正面之前被渲染，从而可以保证正确的渲染关系。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第七章-基础纹理</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E4%B8%83%E7%AB%A0-%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E4%B8%83%E7%AB%A0-%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86/</url>
    
    <content type="html"><![CDATA[<ul><li>纹理最初的目的就是使用一张图片来控制模型的外观。使用<strong>纹理映射</strong>技术，我们可以把一张图“黏”在模型表面，逐<strong>纹素</strong>（纹素的名字是为了与像素作区分）地控制模型的颜色。  </li><li>在美术人员建模时，通常会在建模软件中利用纹理展开技术把<strong>纹理映射坐标</strong>存储到每个顶点上。纹理映射坐标定义了该顶点在纹理中对应的2D坐标。通常，这些坐标使用一个二维变量(u,v)来表示，其中u是横向坐标，而v是纵向坐标。因此，纹理坐标也被称为UV坐标。（原来展UV是这个意思）  </li><li>尽管纹理的大小可以是多种多样的，例如可以是256x256或者1028x1028的，但顶点的UV坐标通常都被归一化到[0,1]范围内。</li><li>注意OpenGL（原点位于左下）和DirectX（原点位于左上）中纹理坐标的不同。</li></ul><h2 id="纹理资源属性"><a href="#纹理资源属性" class="headerlink" title="纹理资源属性"></a>纹理资源属性</h2><h3 id="纹理类型。"><a href="#纹理类型。" class="headerlink" title="纹理类型。"></a>纹理类型。</h3><p>选择合适的类型是为了让unity知道我们的意图，为Unity Shader传递正确的纹理，并在一些情况下可以让Unity对该纹理进行优化。</p><h3 id="Wrap-Mode"><a href="#Wrap-Mode" class="headerlink" title="Wrap Mode"></a>Wrap Mode</h3><p>决定了当纹理坐标超过[0,1]范围后将会如何被平铺。Wrap Mode有两种模式：</p><ul><li>Repeat模式下，纹理坐标超过1，那它的整数部分就会被舍弃，而使用小数部分进行采样，这样的结果是纹理将会不断重复；</li><li>Clamp模式下，如果纹理坐标大于1，那么将会截取到1，如果小于0，那么将会截取到0。<h3 id="Filter-Mode"><a href="#Filter-Mode" class="headerlink" title="Filter Mode"></a>Filter Mode</h3></li><li>它决定了当纹理由于变换而产生拉伸时将会采用哪种滤波模式。Filter Mode支持3种模式：Point、Bilinear、Trilinear。它们得到的图片滤波效果依次上升，但需要耗费的性能也依次增大。纹理滤波会影响放大或缩小纹理得到的图片质量。例如把64X64大小的纹理贴在一个512X512大小的平面上时，就需要放大纹理。纹理缩小的过程比放大更加复杂，此时原纹理多个像素将会对应一个目标像素。纹理缩放更加复杂的原因在于我们往往需要处理锯齿问题，最常用的方法就是多级渐远纹理技术。多级渐远纹理技术是将原纹理提前使用滤波处理来得到很多更小的图像，形成一个图像金字塔，每一层都是对上一层图像降采样的结果。当物体原理摄像机时就可以直接使用较小的纹理。缺点是通常会多占用33%的内存空间。  </li><li>在Unity中，我们将纹理类型选择为Advanced，再勾选Generate Mip Maps即可开启多级渐远纹理技术。</li></ul><p>在内部实现上：</p><ul><li>Point模式使用<strong>最近邻</strong>滤波，在放大缩小时，它的采样像素数目通常只有一个，因此图像会看起来有种像素风格的效果。</li><li>Bilinear滤波则使用了线性滤波，对于每个目标像素，它会找到4个相邻像素，然后对它们进行线性插值混合后得到最终像素，因此图像看起来像被模糊了。</li><li>Trilinear滤波几乎和Bilinear一样，只是Trilinear还会在多级渐远纹理之间进行混合。</li></ul><h2 id="纹理最大尺寸和纹理模式"><a href="#纹理最大尺寸和纹理模式" class="headerlink" title="纹理最大尺寸和纹理模式"></a>纹理最大尺寸和纹理模式</h2><ul><li>Unity允许我们为不同目标平台选择不同的分辨率。<br>如果导入的纹理大小超过了Max Texture Size中设置的值，那么就会被缩放到这个值。导入的纹理可以是非正方形的，但长宽的大小应该是2的幂，如2,4,8,16,32,64,128,512,1024等，如果使用了非2的幂（NPOT）大小的纹理，那么这些纹理往往会占用更多的内存空间，而且GPU读取该纹理的速度也会下降，有些平台甚至不支持NPOT纹理。</li><li>Format决定了Unity内部使用哪种格式来存储该纹理。如果我们将Texture Type设置为Advanced，那么会有更多的Format供我们选择。这里不介绍每种纹理格式，但要知道纹理格式精度越高，越消耗性能，但是得到的效果也越好。</li></ul><h2 id="凹凸映射"><a href="#凹凸映射" class="headerlink" title="凹凸映射"></a>凹凸映射</h2><p>凹凸映射目的是使用一张纹理来修改模型表面的法线，一遍提供更多的细节。这只是让模型看起来好像是凹凸不平的，但可以从模型轮廓看出破绽。<br>目前有两种方法可以用来凹凸映射：</p><ul><li><p>使用<strong>高度纹理</strong>来模拟<strong>表面位移</strong>，然后得到一个修改后的法线值，这种方法被称作<strong>高度映射</strong></p></li><li><p>使用<strong>法线纹理</strong>来直接存储表面法线，这种方法被称作<strong>法线映射</strong></p><h3 id="高度纹理"><a href="#高度纹理" class="headerlink" title="高度纹理"></a>高度纹理</h3><p>使用一张高度图来实现凹凸映射。高度图中存储的是强度值，用于表示表面局部区域的海拔高度。因此颜色越前表示该位置的表面越向外凸起，而颜色越深越向里凹。这种方法好处是直观，可以明确知道一个模型表面的凹凸情况，但缺点是计算更加复杂，实时计算时不能直接得到表面法线，而是需要像素的灰度值计算而得，因此需要消耗更多的性能。<br>高度图通常会和法线映射一起使用，用于给出表面凹凸的额外信息。但通常会使用法线映射来修改光照。</p><h3 id="法线纹理"><a href="#法线纹理" class="headerlink" title="法线纹理"></a>法线纹理</h3><p>由于法线分量范围在[-1,1]，而像素的分量范围为[0,1]，因此我们需要做一个映射，通常使用的映射就是：<br><img src="https://img-blog.csdnimg.cn/2019041623265237.png" alt="向量映射法线公式"><br>反映射就是个逆函数</p></li><li><p>将修改后的模型空间中的表面法线存储在一张纹理中的，这种纹理被称为是<strong>模型空间的法线纹理</strong>。</p></li><li><p>然而通常我们会采用另一种纹理坐标，即模型顶点的切线空间来储存法线。对于模型的每个顶点，它都有一个属于自己的切线空间，原点为该顶点本身，z轴为顶点的法线方向，x轴是顶点的切线方向，y轴可以由法线和切线方向差积得到，被称为副法线或者副切线。这种纹理被称为是<strong>切线空间的法线纹理</strong>。</p></li><li><p>模型空间的法线纹理通常看起来是五颜六色的，而切线空间的法线纹理通常看起来是浅蓝色的</p><h4 id="模型空间储存法线的优点"><a href="#模型空间储存法线的优点" class="headerlink" title="模型空间储存法线的优点"></a>模型空间储存法线的优点</h4></li><li><p>实现简单，更加直观。甚至不需要模型原始的法线和切线等信息，也就是计算更少。生成也非常简单。</p></li><li><p>纹理坐标的缝合处和尖锐的边角部分，可见的突变（缝隙）较少，即可提供平滑边界。因为法线方向存储在同一坐标空间中，所以可以通过插值来平滑变换。</p><h4 id="切线空间储存法线的优点"><a href="#切线空间储存法线的优点" class="headerlink" title="切线空间储存法线的优点"></a>切线空间储存法线的优点</h4></li><li><p>自由度高。模型空间下的法线纹理是<strong>绝对法线信息</strong>，仅可用于创建它的那个模型，应用到其他模型上效果就完全错误了。而切线空间记录的是相对法线信息，这意味着可以把它应用到完全不同的网格上，也可以得到一个合理的结果。</p></li><li><p>可进行UV动画。比如，我们可以移动一个纹理的UV坐标来实现一个凹凸移动的效果，但是使用模型空间的法线纹理就会得到完全错误的结果。这种动画通常会使用在水或火山熔岩这类型的物体上。</p></li><li><p>可以重用法线纹理。比如一个砖块，用一张法线贴图就可以用到所有6个面上。</p></li><li><p>可压缩。由于切线空间下法线的Z方向总是正向，因此可以仅储存XY方向，而推导出Z方向。</p></li></ul><p>(顺手记录一个会用到的第四章的知识点，A坐标空间下，B坐标空间三条坐标轴的单位向量横向排列组成的矩阵就是A坐标空间到B坐标空间的变换矩阵，好像限制条件是没有缩放的情况下)</p><h2 id="Unity中的法线纹理类型"><a href="#Unity中的法线纹理类型" class="headerlink" title="Unity中的法线纹理类型"></a>Unity中的法线纹理类型</h2><p>当我们把法线纹理的纹理类型设置为Normal map时，可以使用Unity的内置函数UnpackNormal来得到正确的法线方向。<br>UnpackNormal的源码为：  </p><figure class="highlight nsis"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><pre><code class="hljs nsis">inline fixed3 Unpack<span class="hljs-params">Normal</span>DXT5nm(fixed4 packed<span class="hljs-params">normal</span>)&#123;<br>    fixed3 <span class="hljs-params">normal</span><span class="hljs-comment">;</span><br>    <span class="hljs-params">normal</span>.xy = packed<span class="hljs-params">normal</span>.wy * <span class="hljs-number">2</span> - <span class="hljs-number">1</span><span class="hljs-comment">;</span><br>    <span class="hljs-params">normal</span>.z = sqrt(<span class="hljs-number">1</span> - saturate(dot(<span class="hljs-params">normal</span>.xy,<span class="hljs-params">normal</span>.xy)))<span class="hljs-comment">;</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-params">normal</span><span class="hljs-comment">;</span><br>&#125;<br><br>inline fixed3 Unpack<span class="hljs-params">Normal</span>(fixed4 packed<span class="hljs-params">normal</span>)&#123;<br>    <span class="hljs-comment">#if define(UNITY_NO_DXT5nm)</span><br>        <span class="hljs-keyword">return</span> packed<span class="hljs-params">normal</span>.xyz * <span class="hljs-number">2</span> - <span class="hljs-number">1</span><span class="hljs-comment">;</span><br>    <span class="hljs-comment">#else</span><br>        <span class="hljs-keyword">return</span> Unpack<span class="hljs-params">Normal</span>DXT5nm(packed<span class="hljs-params">normal</span>)<span class="hljs-comment">;</span><br>    <span class="hljs-comment">#endif</span><br>&#125;<br></code></pre></td></tr></table></figure><ul><li>从代码可以看出，UnpackedNomal函数对使用DXT5nm压缩格式的法线纹理进行的相应解码方式。<br>DXT5nm压缩格式中，纹素的a通道（即w分量）对用了法线的x分量，g通道对应了法线的y分量，而纹理的r和b通道则会被舍弃，法线的z分量可以由xy分量推导得出。使用这种压缩可以减少法线纹理占用的空间。  </li><li>纹理设置中还有一个Create from Grayscale复选框，勾选这个复选框后，这张纹理贴图就被当做高度图来处理。勾选后会增加两个选项——Bumpiness和Filtering。其中Bumpiness用于控制凹凸程度，而Filtering用于控制我们使用哪种方式来计算凹凸程度。<br>一种是Smooth，这使得生成的法线纹理会比较平滑<br>另一种是sharp，它会使用Sobel滤波，来生成法线。Sobel滤波的实现非常简单，我们只需要在一个3x3的滤波器中计算x和y方向上的导数，然后从中得到法线即可。<h2 id="渐变纹理"><a href="#渐变纹理" class="headerlink" title="渐变纹理"></a>渐变纹理</h2>一开始时，人们使用纹理来定义一个物体的颜色，后来人们发现纹理其实可以用来储存任何表面属性。一种常见的用法就是使用渐变纹理来控制漫反射光照的结果。之前的满反射计算时，我们使用表面法线和光照方向的点积乘上物体的反照率来得到的。有时我们需要更灵活地控制光照结果。这种技术在《军团要塞2》中流行起来，也是由Valve公司提出来的。最初由Gooch等人在《A Non-Photorealistic Lighting Model For Automatic Technical Illustration》中被提出。这种技术可以使物体轮廓线更加明显，很多卡通风格的渲染中都使用了这种技术。</li></ul><h2 id="遮罩纹理"><a href="#遮罩纹理" class="headerlink" title="遮罩纹理"></a>遮罩纹理</h2><ul><li>遮罩允许我们保护某些区域，使它们免于某些修改。有时我们希望模型表面某些区域的反光强一些，某些区域弱一些，就可以使用遮罩纹理实现。</li><li>使用遮罩纹理的一般流程：通过采样得到遮罩纹理的纹素值，然后使用其中某个（或某几个）通道的值来与某种表面属性进行相乘，这样，当该通道的值为0时，可以保护表面不受该属性的影响。</li><li>在真实的游戏制作中，遮罩纹理已经不仅局限于保护某些区域使它们免于某些修改，而是可以存储任何我们希望逐像素控制的表面属性。通常一张纹理拥有RGBA四个通道，这意味这我们可以存储4个表面属性到一张纹理中。dota2中模型就有额外的两张纹理用来提供额外的8个表面属性。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第六章-Unity中的基础光照</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%85%AD%E7%AB%A0-Unity%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E5%85%89%E7%85%A7/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%85%AD%E7%AB%A0-Unity%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E5%85%89%E7%85%A7/</url>
    
    <content type="html"><![CDATA[<p>渲染的基础问题就是，我们如何决定一个像素的颜色？<br>宏观上来看，渲染包括两个部分：决定一个像素的可见性，决定这个像素上的光照计算。光照模型就是用于决定在一个像素上进行怎样的光照计算。</p><h2 id="我们是如何看这个世界的"><a href="#我们是如何看这个世界的" class="headerlink" title="我们是如何看这个世界的"></a>我们是如何看这个世界的</h2><p>当我们说一个物体是红色的时候，意味着这个物体会反射更多的红光波，吸收其他的光波。而一个物体看起来是黑色的则是吸收了大部分的光波。<br>模拟真实的光照环境来生成一张图片时，我们需要考虑3种物理现象：</p><ul><li>首相，光从光源(light source)中发射出来</li><li>然后，光线和场景中的一些物体相交：一些光线被吸收了，而另一些光线被散射到其他方向。</li><li>最后，摄像机吸收了一些光，产生一张图像。</li></ul><h2 id="光源"><a href="#光源" class="headerlink" title="光源"></a>光源</h2><p>在实时渲染中，我们通常把光源当成一个没有体积的点，用l来表示它的方向。在光学中，我们使用<strong>辐照度</strong>(irradiance)来量化光。对于平行光，它的辐照度可以通过计算垂直于l的单位面积上单位时间内穿过的能量来得到。在计算光照模型时，我们需要知道一个物体表面的辐照度，而物体表面通常与l不垂直，我们可以使用光源方向l和表面法线之间的夹角余弦值来得到。<br><img src="https://img-blog.csdnimg.cn/20190411173646336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDg2NjM5,size_16,color_FFFFFF,t_70" alt="光照图示"><br>左图中，光线垂直照射到物体表面，因此光线之间距离不变；右图中，光斜照到物体表面，物体表面光线之间的距离是d&#x2F;cosθ，因此单位面积上接受的光线数目少于左图。<br>因为辐照度与物体表面光线之间距离d&#x2F;cosθ成反比，所以辐照度与cosθ成正比。cosθ可以由光线方向与物体表面法线方向的点积得到（需归一化）。</p><h2 id="吸收和散射"><a href="#吸收和散射" class="headerlink" title="吸收和散射"></a>吸收和散射</h2><p>通常光线与物体表面相交后有两个结果，吸收和散射。  </p><ul><li><strong>散射</strong>只改变光线的方向，但不改变光线的密度和颜色。</li><li><strong>吸收</strong>只改变光线的密度和颜色，但不改变光线的方向。</li></ul><h3 id="散射"><a href="#散射" class="headerlink" title="散射"></a>散射</h3><p>光线在物体表面经过散射后，有两种方向：一种是散射到物体内部，这种现象被称为<strong>折射</strong>或<strong>透射</strong>  ；另一种会散射到外部，这种现象被称为<strong>反射</strong>。<br>对于不透明物体，折射进入物体内部的光线还会继续与内部的颗粒进行相交，其中一些光线最后会重新发射出物体表面，另一些则被物体吸收。重新从物体发射出的光线与射入光线有不同的方向分布和颜色。  </p><ul><li><strong>高光反射</strong>用来表示物体表面如何进行反射。</li><li><strong>漫反射</strong>表示有多少光线被折射、吸收和散射出表面。</li><li>根据入射光线的数量和方向，我们可以计算出射光线的数量和方向，通常使用<strong>出射度</strong>来描述它。<br>辐照度和出射度之间是满足线性关系的，而他们之间的比值就是材质的漫反射和高光反射。<br>ps：本章中，我们先假设漫反射无方向，即均匀分布到各个方向；同时也只考虑某一个特定方向的高光反射。</li></ul><h3 id="着色"><a href="#着色" class="headerlink" title="着色"></a>着色</h3><ul><li><strong>着色</strong>指，根据材质属性（如漫反射等）、光源信息（如光源方向、辐照度）等，使用一个等式去计算沿某个观察方向的出射度的过程。我们也把这个等式称为<strong>光照模型</strong>。不同的光照模型有不同的用途。例如，一些用于描述粗糙的物体表面，一些用于描述金属表面。</li></ul><h3 id="BRDF光照模型"><a href="#BRDF光照模型" class="headerlink" title="BRDF光照模型"></a>BRDF光照模型</h3><ul><li>在图形学中<strong>BRDF</strong>大多使用一个数学公式来表示，并且提供了一些参数来调整材质属性。通俗来讲，给定入射光线的光线和辐照度后，BEDF就可以给出在某个出射方向上的光照能量分布。</li><li>本章涉及的BRDF都是对真实场景进行理想化和简化后的模型。意味着这些模型任然不能模拟真实光照，这些光照模型被称为经验模型。尽管如此，这些模型任在实时渲染领域被应用了多年。在邓恩的著作《3D数学基础：图形与游戏开发》中提到一句名言：<br>  <strong>计算机图形学的第一定律：如果它看起来是对的，那么它就是对的。</strong><h2 id="标准光照模型"><a href="#标准光照模型" class="headerlink" title="标准光照模型"></a>标准光照模型</h2></li><li>它在BDRF理论提出前就已经被广泛使用了。它只关心直接光照，也就是那些直接从光源发射出来照射到物体表面后经过一次反射直接进入摄像机的光线。</li><li>它的基本方法把进入摄像机的光线分为4个部分，每个部分使用一种方法来计算它的贡献度：</li></ul><p><strong>自发光</strong>之后使用 <strong>C<sub>missive</sub></strong> 来表示。用于描述给定一个方向后，一个表面会向这个方向发射多少辐射量。如果没有使用<strong>全局光照</strong>技术，这些自发光的表面并不会真的照亮周围的物体<br><strong>高光反射</strong>之后使用 <strong>C<sub>specular</sub></strong> 来表示。用于描述当光线从光源照射到模型表面时，该表面会在完全镜面反射方向散射多少辐射量。<br><strong>漫反射</strong>之后使用 <strong>C<sub>diffuse</sub></strong> 来表示。用于描述当光线从光源照射到模型表面是，该表面会向每个方向散射多少辐射量。<br><strong>环境光</strong>之后使用 <strong>C<sub>ambient</sub></strong> 来表示。用于描述其他所有间接光。  </p><h3 id="环境光"><a href="#环境光" class="headerlink" title="环境光"></a>环境光</h3><p>标准光照模型重点在于描述直接光照，但现实世界中，物体也会被间接光照所照亮。间接光照指，光线进入摄像机之前，在多个物体间反射，经过了不止一次物体反射。<br>标准光照模型中，环境光通常使用一个全局变量，场景中所有物体都使用这个环境光。<br><strong>C<sub>ambient</sub>&#x3D;g<sub>ambient</sub></strong></p><h3 id="自发光"><a href="#自发光" class="headerlink" title="自发光"></a>自发光</h3><p>光线也可以直接由光源发射进入摄像机，而不需经过任何物体的反射。标准光照模型使用自发光来计算这个部分的贡献度。它的计算也很简单，直接使用这个物体自发光的颜色。<br><strong>C<sub>emissive</sub>&#x3D;m<sub>emissive</sub></strong><br>通常在实时光照中，自发光不会照亮其他表面，也就是这个物体不会被当成一个光源。Unity5中引入的全新的全局光照系统可以模拟这类自发光对周围物体的影响，在18章中我们会看到。（好遥远啊，怎么才第六章）</p><h3 id="漫反射"><a href="#漫反射" class="headerlink" title="漫反射"></a>漫反射</h3><p>漫反射光是对物体表面随机散射到各个方向的辐射度进行建模的。在漫反射中，视角的位置不重要，因为方向完全随机，我们可以假设在任何方向上的分布都是一样的。但是入射光线的角度很重要。<br>满反射符合<strong>兰伯特定律</strong>：反射光线的强度与表面法线和光源之间的夹角余弦值成正比。<br><strong>C<sub>diffuse</sub>&#x3D;(C<sub>light</sub>·m<sub>diffuse</sub>)max(0,n·I)</strong><br>n:表面法线<br>I:指向光源的单位矢量<br>m<sub>diffuse</sub>:材质的漫反射颜色<br>C<sub>light</sub>:光源颜色<br>我们要防止法线和光源方向点乘结果为负值，所以使用max函数，最低取0，防止表面被来自后面的光照亮。</p><h3 id="高光反射"><a href="#高光反射" class="headerlink" title="高光反射"></a>高光反射</h3><p>这里的高光反射为经验模型。它可以用于计算那些沿着完全镜面反射方向被反射的光线，这可以让物体看起来有光泽，例如金属材质。<br>高光反射的计算需要知道的信息较多，表面法线、视角方向、光源方向、反射方向等。本节中假设这些都是单位矢量。<br>四个矢量中我们只需要知道3个就足够了,反射方向可以通过其他3个矢量求出。<br><img src="https://img-blog.csdnimg.cn/2019041121141433.png" alt="反射方向公式">  </p><ul><li>利用Pong模型计算高光反射:<br><img src="https://img-blog.csdnimg.cn/20190411222242890.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDg2NjM5,size_16,color_FFFFFF,t_70" alt="pong模型"><br><img src="https://img-blog.csdnimg.cn/20190411212333447.png" alt="Pong模型"><br>其中m<sub>gloss</sub>为材质的光泽度，也被称为反光度。它用于控制高光区域的“亮点”有多宽m<sub>gloss</sub>越大，亮点越小。<br>m<sub>specular</sub>是材质的高光反射颜色，它用于控制该材质对于高光反射的强度和颜色。<br>v是指向摄像机方向的向量。</li><li>利用Blinn模型计算高光反射：<br><img src="https://img-blog.csdnimg.cn/20190411222725398.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDg2NjM5,size_16,color_FFFFFF,t_70" alt="Blinn模型"><br><img src="https://img-blog.csdnimg.cn/20190411222820145.png" alt="Blinn模型"><br>与Pong模型相比，Blinn模型提出了一个简单的方法修改来得到类似的效果。这个方法避免了对反射方向的计算，引入了一个新的矢量h，通过对I和v取平均后归一化得到的。<br><img src="https://img-blog.csdnimg.cn/20190411223256692.png" alt="h计算公式"><br>然后使用n和h计算。</li></ul><p><em>（我个人的理解是，Pong模型中r和v的夹角与n和I有关，r是I相对于n的镜像，Blinn中的h计算也与v和I有关，当光线入射角变大时，这两个模型中的夹角都变大，虽然增长比例不同但都是线性增长，表现出来的效果类似，相当于是对前文邓恩的那句话的体现了）</em><br>摄像机和光源距离表面较近时，使用blinn模型更快些（v和I近似为定值，则h便为一个常量），反之Pong要快些。两者都是经验模型，没有谁更准确的说法。</p><h3 id="逐像素还是逐顶点"><a href="#逐像素还是逐顶点" class="headerlink" title="逐像素还是逐顶点"></a>逐像素还是逐顶点</h3><p>对于上面给出的基本光照模型的公式的应用，我们有两种选择:</p><ul><li>在片元着色器中计算，被称为<strong>逐像素光照</strong></li><li>在顶点着色器中计算，被称为<strong>逐顶点光照</strong><h4 id="逐像素光照"><a href="#逐像素光照" class="headerlink" title="逐像素光照"></a>逐像素光照</h4>逐像素光照中，我们会以每个像素为基础，得到它的法线（对顶点法线插值得到或者从法线纹理中采样得到），进行光照模型计算。这种面片之间对顶点插值的技术成为Pong着色，也成为Pong插值或法线插值，不同于Pong光照模型。<h4 id="逐顶点光照"><a href="#逐顶点光照" class="headerlink" title="逐顶点光照"></a>逐顶点光照</h4>也被称为高罗德着色（Gouraud shading）。在逐顶点光照中，我们在每个顶点上计算光照，然后会在渲染图元内部进行插值，最后输出成像素颜色。顶点数目永远小于像素数目，所以计算次数比逐像素光照要少。但是逐顶点光照过于依赖线性插值来的到像素光照，光照模型中有非线性的计算时（例如计算高光反射时），逐顶点光照就会出问题。因为是线性插值，顶点处颜色最深，在某些情况下会产生明显的棱角现象。</li></ul><h2 id="Unity中的环境光和自发光"><a href="#Unity中的环境光和自发光" class="headerlink" title="Unity中的环境光和自发光"></a>Unity中的环境光和自发光</h2><p>在标准光照模型中，环境光和自发光的计算是最简单的。<br>在shader中，我们只需要通过Unity的内置变量UNITY_LIGHTMODEL_AMBIENT就可以得到环境光的颜色和强度信息。<br>而大多数物体是没有自发光特性的，因此在书中绝大部分的shader中都不计算自发光。</p><h2 id="在Unity-Shader中实现漫反射光照模型"><a href="#在Unity-Shader中实现漫反射光照模型" class="headerlink" title="在Unity Shader中实现漫反射光照模型"></a>在Unity Shader中实现漫反射光照模型</h2><p><strong>C<sub>diffuse</sub>&#x3D;(C<sub>light</sub>·m<sub>diffuse</sub>)max(0,n·I)</strong><br>根据公式可知，我们需要知道4个参数：入射光线的颜色和强度C<sub>light</sub>，材质的漫反射系数m<sub>diffuse</sub>，表面法线n以及光源方向I。<br>为防止点积结果为负数，我们需要max操作，而CG提供了这样一个函数。</p><ul><li>函数：saturate(x)</li><li>参数：x：为用于操作的标量或者矢量，可以使float、float2、float3等类型。</li><li>描述：把x截取在[0,1]范围内，如果x是一个矢量，那么会对它的每一个分量进行这样的操作。<br>（由于是个人笔记，里面的范例我就不记录了，范例可以在书中6.4.1和6.4.2节看到）</li></ul><h2 id="在Unity-Shader中实现高光反射光照模型"><a href="#在Unity-Shader中实现高光反射光照模型" class="headerlink" title="在Unity Shader中实现高光反射光照模型"></a>在Unity Shader中实现高光反射光照模型</h2><p><img src="https://img-blog.csdnimg.cn/20190411212333447.png" alt="Pong模型"><br>从公式可以看出，计算高光反射需要知道4个参数：入射光线的颜色和强度、材质的高光反射系数、视角方向和反射方向。其中，反射方向可以由表面法线和光源方向计算而得。<br><img src="https://img-blog.csdnimg.cn/2019041121141433.png" alt="反射方向公式"><br>CG提供了计算反射方向的函数reflect。</p><ul><li>函数：reflect(i,n)</li><li>参数：i，入射方向；n，法线方向。可以是float、float2、float3等类型。</li><li>描述：当给定入射方向i和法线方向n时，reflect函数可以返回反射方向。<br>（由于是个人笔记，里面的范例我就不记录了，范例可以在书中6.5.1和6.5.2节看到）</li></ul><h2 id="UnityCG-cginc中一些常用的帮助函数"><a href="#UnityCG-cginc中一些常用的帮助函数" class="headerlink" title="UnityCG.cginc中一些常用的帮助函数"></a>UnityCG.cginc中一些常用的帮助函数</h2><table><thead><tr><th>函数名</th><th>描述</th></tr></thead><tbody><tr><td>float3 WorldSpaceViewDir(float4 v)</td><td>输入一个模型空间中的顶点位置，返回世界空间中从该点到摄像机的观察方向。（内部实现使用了UnityWorldSpaceViewDir函数）</td></tr><tr><td>float3 UnityWorldSpaceViewDir(float4 v)</td><td>输入一个世界空间中的顶点位置，返回世界空间中从该点到摄像机的观察方向。（内部实现使用了UnityWorldSpaceViewDir函数</td></tr><tr><td>float3 ObjSpaceViewDir(float4 v)</td><td>输入一个模型空间中的顶点位置，返回模型空间中从该点到摄像机的观察方向</td></tr><tr><td>float3 WorldSpaceLightDir(float4 v)</td><td>仅可用于前向渲染。输入一个模型空间中的顶点位置，返回世界空间中从该点到光源的光照方向。没有被归一化。（内部实现使用了UnityWorldSpaceViewDir函数）</td></tr><tr><td>float3 UnityWorldSpaceViewDir(float4 v)</td><td>仅可用于前向渲染。输入一个世界空间中的顶点位置，返回世界空间中从该点到光源的光照方向。没有被归一化。</td></tr><tr><td>float3 ObjSpaceLightDir(float4 v)</td><td>仅可用于前向渲染中。输入一个模型空间中的顶点位置，返回模型空间中从该点到光源的光照方向。没有被归一化。</td></tr><tr><td>float3 UnityObjectToWorldNormal(float3 norm)</td><td>把法线方向从模型空间转换到世界空间中</td></tr><tr><td>float3 UnityObjectToWorldDir(in float3 dir)</td><td>把矢量方向从模型空间变换到世界空间中</td></tr><tr><td>float3 UnityWorldToObjectDit(float3 dir)</td><td>把矢量方向从世界空间变换到模型空间中</td></tr></tbody></table><h4 id="ps：注意这些函数都没有进行归一化，我们在使用前需要进行归一化处理。"><a href="#ps：注意这些函数都没有进行归一化，我们在使用前需要进行归一化处理。" class="headerlink" title="ps：注意这些函数都没有进行归一化，我们在使用前需要进行归一化处理。"></a>ps：注意这些函数都没有进行归一化，我们在使用前需要进行归一化处理。</h4>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第五章-开始学习UnityShader之旅</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E4%BA%94%E7%AB%A0-%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0UnityShader%E4%B9%8B%E6%97%85/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E4%BA%94%E7%AB%A0-%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0UnityShader%E4%B9%8B%E6%97%85/</url>
    
    <content type="html"><![CDATA[<h2 id="最简单的片元着色器"><a href="#最简单的片元着色器" class="headerlink" title="最简单的片元着色器"></a>最简单的片元着色器</h2><p><img src="https://img-blog.csdnimg.cn/20190404173615767.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDg2NjM5,size_16,color_FFFFFF,t_70" alt="最简单的片元着色器代码"></p><figure class="highlight arduino"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> vertex vert</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> fragment frat</span><br></code></pre></td></tr></table></figure><p>告诉Unity那个函数包括顶点着色器的代码，哪个函数包括片元着色器的代码。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs scss">float4 <span class="hljs-built_in">vert</span>(float4 v : POSITION) SV_POSITION&#123;<br>    return <span class="hljs-built_in">mul</span>(UNITY_MATRIX_MVP,v);<br>&#125;<br></code></pre></td></tr></table></figure><p>vert 中包含了这个顶点的位置，这是通过 POSITION 语义定义的。<br>输出值为裁切空间中的顶点坐标，这是通过 SV_POSITION 语义定义的。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-comment">//使用一个结构体来定义顶点着色器的输入</span><br>struct a2v &#123;<br><span class="hljs-comment">//POSITION 语义告诉 Unity，用模型空间的顶点坐标填充vertex变量</span><br>float4 vertex : POSITION;<br><span class="hljs-comment">//NORMAL 语义告诉Unity，用模型空间的法线方向填充normal变量</span><br>float3 noremal : NORMAL;<br><span class="hljs-comment">//TEXCOORD0语义告诉Unity，用模型的第一套纹理坐标填充texcoord变量</span><br>float4 texcoord : TEXCOORD0;<br>&#125;;<br><br>float4 <span class="hljs-built_in">vert</span>(a2v v) : SV_POSITION &#123;<br>return <span class="hljs-built_in">UnityObjectToClipPos</span>(v.vertex);<br>&#125;<br></code></pre></td></tr></table></figure><p>需要获取多个顶点信息，需要创建一个结构，并且作为参数传递给顶点着色器代码块。  </p><h3 id="顶点着色器与片元着色器通信"><a href="#顶点着色器与片元着色器通信" class="headerlink" title="顶点着色器与片元着色器通信"></a>顶点着色器与片元着色器通信</h3><p>在顶点着色器代码块中，返回值输出一个与片元着色器参数类型相同的结构体。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">v2f <span class="hljs-title">vert</span><span class="hljs-params">(a2v v)</span></span><br><span class="hljs-function"></span>&#123;<br>v2f o;<br>o.pos = <span class="hljs-built_in">UnityObjectToClipPos</span> (v.vertex);<br>o.color = v.normal * <span class="hljs-number">0.5</span> + <span class="hljs-built_in">fixed3</span>(<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>);<br><span class="hljs-keyword">return</span> o;<br><br><span class="hljs-function">fixed4 <span class="hljs-title">frag</span><span class="hljs-params">(v2f i)</span> : SV_Target</span><br><span class="hljs-function">&#123;</span><br><span class="hljs-keyword">return</span> <span class="hljs-built_in">fixed4</span>(i.color, <span class="hljs-number">1.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="如何使用属性"><a href="#如何使用属性" class="headerlink" title="如何使用属性"></a>如何使用属性</h3><p>Properties语义块中可以定义一些参数由编辑器的材质面板调节。</p><ul><li>首先我们添加了Properties语义块，并在其中声明一个属性_Color，它的类型是Color，初始值是(1.0,1.0,1.0,1.0);</li><li>为了在CG代码中访问他，我们需要在CG代码中提前定义一个变量，变量名称和类型必须与Properties语义块中的属性定义相匹配。  <h4 id="ShaderLab属性类型和CG变量类型的匹配关系"><a href="#ShaderLab属性类型和CG变量类型的匹配关系" class="headerlink" title="ShaderLab属性类型和CG变量类型的匹配关系"></a>ShaderLab属性类型和CG变量类型的匹配关系</h4></li></ul><table><thead><tr><th>ShaderLab属性类型</th><th>CG变量类型</th></tr></thead><tbody><tr><td>Color,Vector</td><td>float4,half4,fixed4</td></tr><tr><td>Range,Float</td><td>float,half,fixed</td></tr><tr><td>2D</td><td>sampler2D</td></tr><tr><td>Cube</td><td>samplerCube</td></tr><tr><td>3D</td><td>sampler3D</td></tr></tbody></table><h2 id="Unity-提供的内置文件和变量"><a href="#Unity-提供的内置文件和变量" class="headerlink" title="Unity 提供的内置文件和变量"></a>Unity 提供的内置文件和变量</h2><p>包含文件，类似c++中的头文件的一种。在Unity中它们的后缀为.cginc。使用#include可以把它们包含进来。<br>这些文件可以在<a href="http://unity3d.com/cn/get-unity/download/archive">官方网站</a>上选择下载-&gt;内置着色器来直接下载。这些文件是非常好的参考资料，在我们想要学习内置着色器的实现或是寻找内置函数的实现时，都可以在这里找到内部实现。<br>我们可以直接在Unity的应用程序中找到<br>Mac:&#x2F;Application&#x2F;Unity&#x2F;Unity.app&#x2F;Content&#x2F;CGIncludes<br>Windows:Unity安装路径&#x2F;Data&#x2F;CGIncludes</p><h4 id="Unity中一些常用的包含文件"><a href="#Unity中一些常用的包含文件" class="headerlink" title="Unity中一些常用的包含文件"></a>Unity中一些常用的包含文件</h4><table><thead><tr><th>文件名</th><th>描述</th></tr></thead><tbody><tr><td>UnityCG.cginc</td><td>包含了最常使用的帮助函数、宏和结构体</td></tr><tr><td>UnityShaderVariables.cginc</td><td>在编译Unity Shader时，会被自动包含进来。包含了许多内置的全局变量，如UNITY_MATRIX_MVP等</td></tr><tr><td>Lighting.cginc</td><td>包含了各种内置的光照模型，如果编写的是Surface Shader的话，会自动包含进来</td></tr><tr><td>HLSLSupport.cginc</td><td>在编译Unity Shader时，会自动包含进来。声明了很多用于跨平台编译的宏和定义</td></tr></tbody></table><p>UnityCG.cginc 是最常接触的一个包含文件。</p><h4 id="UnityCG-cginc中一些常用的结构体"><a href="#UnityCG-cginc中一些常用的结构体" class="headerlink" title="UnityCG.cginc中一些常用的结构体"></a>UnityCG.cginc中一些常用的结构体</h4><table><thead><tr><th>名称</th><th>描述</th><th>包含的变量</th></tr></thead><tbody><tr><td>appdata_base</td><td>可用于顶点着色器的输入</td><td>顶点位置、顶点法线、第一组纹理坐标</td></tr><tr><td>appdata_tan</td><td>可用于顶点着色器的输入</td><td>顶点位置、顶点切线、顶点法线、第一组纹理坐标</td></tr><tr><td>appdata_full</td><td>可用于顶点着色器的输入</td><td>顶点位置、顶点切线、顶点法线、四组（或更多）纹理坐标</td></tr><tr><td>appdata_img</td><td>可用于顶点着色器的输入</td><td>顶点位置、第一组纹理坐标</td></tr><tr><td>v2f_img</td><td>可用于顶点着色器的输出</td><td>裁剪空间中的位置、纹理坐标</td></tr></tbody></table><h4 id="UnityCG-cginc中一些常用的帮助函数"><a href="#UnityCG-cginc中一些常用的帮助函数" class="headerlink" title="UnityCG.cginc中一些常用的帮助函数"></a>UnityCG.cginc中一些常用的帮助函数</h4><table><thead><tr><th>函数名</th><th>描述</th></tr></thead><tbody><tr><td>float3 WorldSpaceViewDir(float4 v)</td><td>输入一个模型空间中的顶点位置，返回世界空间中从该点到摄像机的观察方向</td></tr><tr><td>float3 ObjSpaceViewDir(float4 v)</td><td>输入一个模型空间中的顶点位置，返回模型空间中从该点到摄像机的观察方向</td></tr><tr><td>float3 WorldSpaceLightDir(float4 v)</td><td>仅可用于前向渲染。输入一个模型空间中的额顶点位置，返回世界空间中从该点到光源的光照方向。没有被归一化。</td></tr><tr><td>float3 ObjSpaceLightDir(float4 v)</td><td>仅可用于前向渲染中。输入一个模型空间中的顶点位置，返回模型空间中从该点到光源的光照方向。没有被归一化。</td></tr><tr><td>float3 UnityObjectToWorldNormal(float3 norm)</td><td>把法线方向从模型空间转换到世界空间中</td></tr><tr><td>float3 UnityObjectToWorldDir(in float3 dir)</td><td>把矢量方向从模型空间变换到世界空间中</td></tr><tr><td>float3 UnityWorldToObjectDit(float3 dir)</td><td>把矢量方向从世界空间变换到模型空间中</td></tr></tbody></table><h2 id="Unity-提供的CG-x2F-HLSL语义"><a href="#Unity-提供的CG-x2F-HLSL语义" class="headerlink" title="Unity 提供的CG&#x2F;HLSL语义"></a>Unity 提供的CG&#x2F;HLSL语义</h2><h3 id="什么是语义"><a href="#什么是语义" class="headerlink" title="什么是语义"></a>什么是语义</h3><p>语义可以让Shader知道从哪里读取数据，并把数据输出到哪<br>之前代码中的POSITION NORMAL SV_POSIONT 等就是语义</p><h3 id="Unity-支持的语义"><a href="#Unity-支持的语义" class="headerlink" title="Unity 支持的语义"></a>Unity 支持的语义</h3><h4 id="从应用阶段传递模型数据给顶点着色器时Unity支持的常用语义"><a href="#从应用阶段传递模型数据给顶点着色器时Unity支持的常用语义" class="headerlink" title="从应用阶段传递模型数据给顶点着色器时Unity支持的常用语义"></a>从应用阶段传递模型数据给顶点着色器时Unity支持的常用语义</h4><table><thead><tr><th>语义</th><th>描述</th></tr></thead><tbody><tr><td>POSITION</td><td>模型空间中的顶点位置，通常是float4类型</td></tr><tr><td>NORMAL</td><td>顶点法线，通常是float3类型</td></tr><tr><td>TANGENT</td><td>顶点切线，通常是float4类型</td></tr><tr><td>TEXCOORDn，如TEXCOORD0、TEXCOORD1</td><td>该顶点的纹理坐标，TEXCOORD0表示第一组纹理坐标，以此类推。通常是float2或float4类型</td></tr><tr><td>COLOR</td><td>顶点颜色，通常是fixed4或float4类型</td></tr></tbody></table><h4 id="从顶点着色器传递数据给片元着色器时Unity使用的常用语义"><a href="#从顶点着色器传递数据给片元着色器时Unity使用的常用语义" class="headerlink" title="从顶点着色器传递数据给片元着色器时Unity使用的常用语义"></a>从顶点着色器传递数据给片元着色器时Unity使用的常用语义</h4><table><thead><tr><th>语义</th><th>描述</th></tr></thead><tbody><tr><td>SV_POSITION</td><td>裁剪空间中的坐标顶点，结构体中必须包含一个用该语义修饰的变量。等同于DirectX9中的POSITION，但最好使用SV_POSITION</td></tr><tr><td>COLOR0</td><td>通常用于输出第一组顶点颜色，但不是必须的</td></tr><tr><td>COLOR1</td><td>通常用于输出第二组顶点颜色，但不是必须的</td></tr><tr><td>TEXCOORD0~TEXCOORD7</td><td>通常用于输出纹理坐标，但不是必须的</td></tr></tbody></table><h4 id="片元着色器输出时Unity支持的常用语义"><a href="#片元着色器输出时Unity支持的常用语义" class="headerlink" title="片元着色器输出时Unity支持的常用语义"></a>片元着色器输出时Unity支持的常用语义</h4><table><thead><tr><th>语义</th><th>描述</th></tr></thead><tbody><tr><td>SV_Target</td><td>输出值将会存储到渲染目标(render target)中。等同于DirexX 9中的COLOR语义，但最好使用SV_Target</td></tr></tbody></table><h2 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h2><p>可以将法线，切线向量值对应到RGB颜色值，然后在画面颜色显示中来判断。<br>使用Unity中的帧调试器(Window-&gt;Frame Debugger)可以更方便进行调试。</p><h3 id="帧调试器"><a href="#帧调试器" class="headerlink" title="帧调试器"></a>帧调试器</h3><ul><li>最上面的区域可以控制帧调试器开关，开启时滑动条可以重放渲染事件。如果选中的Draw Call是对一个纹理的渲染操作，这个渲染纹理就会显示在Game视图中。而且右侧面板上方可以选择只显示R、G、B、A之一。</li><li>左侧的区域显示了所有事件的树状图，这个树状图中，每个叶子节点就是一个事件。我们可以从事件的命名了解这个事件的操作，例如Draw开头的事件通常就是一次Draw Call。</li><li>右侧窗口显示事件的细节，例如几何图形的细节以及使用了哪个shader。</li></ul><h4 id="如果想要得到更多信息，还是需要使用外部工具。"><a href="#如果想要得到更多信息，还是需要使用外部工具。" class="headerlink" title="如果想要得到更多信息，还是需要使用外部工具。"></a>如果想要得到更多信息，还是需要使用外部工具。</h4><h2 id="渲染平台的差异"><a href="#渲染平台的差异" class="headerlink" title="渲染平台的差异"></a>渲染平台的差异</h2><p>Unity的有点之一就是跨平台性很强，写一份代码就可以在多平台上运行。但绝大多数情况下，Unity为我们隐藏了这些细节，但有时候我们还是需要自己处理。</p><h3 id="渲染纹理的坐标差异"><a href="#渲染纹理的坐标差异" class="headerlink" title="渲染纹理的坐标差异"></a>渲染纹理的坐标差异</h3><ul><li>OpenGL和DirectX中的屏幕坐标存在差异，OpenGL中坐标(0,0)点在左下角，而DirectX中为左上角。<br>大多数情况下，这并不会对我们造成影响。当我们开启了抗锯齿并且需要处理多张渲染图像时。在DirectX中，我们就需要在顶点着色器中翻转某些渲染纹理，例如：</li></ul><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sqf"><span class="hljs-meta">#if UNITY_UV_STARTS_AT_TOP</span><br><span class="hljs-keyword">if</span>(<span class="hljs-variable">_MainTex_TexelSize</span>.y &lt; <span class="hljs-number">0</span>)&#123;<br>    uv.y = <span class="hljs-number">1</span> - uv.y;<br>&#125;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br></code></pre></td></tr></table></figure><p>其中UNITY_UV_STARTS_AT_TOP用来判断当前平台是不是DirectX类型的平台。通过判断_MainTex_TexelSize.y是否小于0来判断是否打开了抗锯齿。</p>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第四章-学习Shader所需的数学基础</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%AD%A6%E4%B9%A0Shader%E6%89%80%E9%9C%80%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%AD%A6%E4%B9%A0Shader%E6%89%80%E9%9C%80%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h2 id="笛卡尔坐标系"><a href="#笛卡尔坐标系" class="headerlink" title="笛卡尔坐标系"></a>笛卡尔坐标系</h2><h3 id="三维笛卡尔坐标系"><a href="#三维笛卡尔坐标系" class="headerlink" title="三维笛卡尔坐标系"></a>三维笛卡尔坐标系</h3><ul><li>左手坐标系</li><li>右手坐标系<h3 id="Unity使用的坐标系"><a href="#Unity使用的坐标系" class="headerlink" title="Unity使用的坐标系"></a>Unity使用的坐标系</h3></li><li>模型空间 左手坐标系</li><li>世界空间 左手坐标系</li><li>观察空间 右手坐标系，摄像机前向是z轴的负方向。<h2 id="坐标变换"><a href="#坐标变换" class="headerlink" title="坐标变换"></a>坐标变换</h2></li><li>模型空间变换到世界空间中，这个变换叫做模型变换。</li><li>世界空间变换的观察空间，这个变换叫做观察变换。</li><li>观察空间变换到裁剪空间（齐次剪切空间），这个变换的矩阵叫做裁剪矩阵，也被称为投影矩阵。<br>裁剪空间由视锥体决定<br>视锥体定义了场景内的一个坐标空间，只有空间内的物体会被渲染，Camera中的设置影响这个空间。  <h3 id="透视投影"><a href="#透视投影" class="headerlink" title="透视投影"></a>透视投影</h3>FOV为视锥体纵向张开角度<br>Near决定近裁剪平面距离相机的距离<br>Far决定远裁剪平面距离相机的距离<br>Viewport Rect中的W，H属性共同决定纵横比<br>变换后若一点在空间内，则：</li></ul><p>-w &lt;&#x3D; x &lt;&#x3D; w<br>-w &lt;&#x3D; y &lt;&#x3D; w<br>-w &lt;&#x3D; z &lt;&#x3D; w</p><h3 id="正交投影"><a href="#正交投影" class="headerlink" title="正交投影"></a>正交投影</h3><p>Size决定视锥体竖直方向上高度的一半<br>Near决定近裁剪平面距离相机的距离<br>Far决定远裁剪平面距离相机的距离  </p><ul><li>视锥体投影到屏幕空间中，我们便会的得到真正的像素位置，而不是虚拟的三维坐标<br>我们需要先进行齐次除法：用w分量去处理x,y,z分量，得到归一化的设备坐标。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第三章-UnityShader基础</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E4%B8%89%E7%AB%A0-UnityShader%E5%9F%BA%E7%A1%80/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E4%B8%89%E7%AB%A0-UnityShader%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h2 id="shader和材质"><a href="#shader和材质" class="headerlink" title="shader和材质"></a>shader和材质</h2><h3 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h3><ul><li>创建材质</li><li>创建unity shader，并赋给创建的材质</li><li>将材质赋给要渲染的对象</li><li>在材质面板调整Unity Shader属性。<h3 id="Unity-Shader-模板："><a href="#Unity-Shader-模板：" class="headerlink" title="Unity Shader 模板："></a>Unity Shader 模板：</h3></li><li>standard surface shader：包含了标准光照模型的表面着色器模板</li><li>unlit shader：不含光照的基本顶点&#x2F;片元着色器</li><li>image effect shader：实现屏幕后处理效果基本模板<h2 id="ShaderLab"><a href="#ShaderLab" class="headerlink" title="ShaderLab"></a>ShaderLab</h2><h3 id="unity-shader-基本结构"><a href="#unity-shader-基本结构" class="headerlink" title="unity shader 基本结构"></a>unity shader 基本结构</h3></li><li>Properties{} 属性</li><li>SubShader{} 显卡使用的子着色器</li><li>Fallback “” <h4 id="Properties-属性"><a href="#Properties-属性" class="headerlink" title="Properties{} 属性"></a>Properties{} 属性</h4></li><li>每个属性有名字，通常由下划线开始</li><li>显示的名称，出现在材质面板上的名字</li><li>类型</li><li>属性格式： 名字 (“显示名字”,属性类型) &#x3D; 初始值<br>即使我们没在Properties中定义属性，也可以在CG语言中定义属性。在Properties中定义属性是为了在编辑器中可以显示。<h4 id="SubShader"><a href="#SubShader" class="headerlink" title="SubShader{}"></a>SubShader{}</h4></li><li>每一个Unity Shader文件中可以包含多个SubShader{}，但最少要有一个。</li><li>Unity需要加载这个Unity Shader时，会扫描所有SubShader{}，选择第一个可以在目标平台中运行的SubShader{}。如果都不支持，Unity就会使用在Fallback语义定义的Unity Shader。</li><li>SubShader基本结构</li></ul><figure class="highlight awk"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><pre><code class="hljs awk">Subshader &#123;<br>    <span class="hljs-regexp">//</span>可选的<br>    [Tags]<br>    <br>    <span class="hljs-regexp">//</span>可选的<br>    [RenderSetup]<br>    <br>    Pass&#123;<br>    &#125;<br>    <span class="hljs-regexp">//</span>Other Passes<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>每个Pass定义一次完整的渲染流程，数量过多会导致性能下降。<h5 id="状态设置"><a href="#状态设置" class="headerlink" title="状态设置"></a>状态设置</h5>状态名称 | 设置指令 | 解释</li></ul><p>—|—|—|<br>Cull | Cull Back\Front\Off | 设置剔除模式：剔除背面\正面\关闭剔除<br>ZTest | ZTest Less Greater\LEqual\GEqual\Equal\NotEqual\Always | 设置深度测试时使用的函数<br>ZWrite | ZWrite On\Off | 开启\关闭深度写入<br>Blend | Blend SrcFactor DstFactor | 开启关闭设置混合模式</p><h4 id="SubShader标签"><a href="#SubShader标签" class="headerlink" title="SubShader标签"></a>SubShader标签</h4><ul><li>是一个键值对，键和值都是字符串。</li><li>告诉Unity渲染引擎，我希望怎样以及何时渲染这个对象。<br><img src="https://img-blog.csdnimg.cn/2019040113403669.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDg2NjM5,size_16,color_FFFFFF,t_70" alt="SubShader标签类型"><br>以上标签仅可在SubShader中声明，而不可以在Pass块中声明。Pass块虽然可以定义标签，但是标签类型不同于SubShader中的标签。<h4 id="Pass语句块"><a href="#Pass语句块" class="headerlink" title="Pass语句块"></a>Pass语句块</h4><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">Pass &#123;<br><span class="hljs-string">    [Name]</span><br><span class="hljs-string">    [Tags]</span><br><span class="hljs-string">    [RenderSetup]</span><br>    <span class="hljs-comment">//Other code</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li>我们可以定义该Pass的名称<br>Name “MyPassName”<br>通过这个名称，我们可以使用UsePass来直接使用其他Unity Shader中的Pass。<br>UsePass “MyShader&#x2F;MYPASSNAME”<br>ps:Unity内部会把pass名称转化成大写字母</li><li>Pass标签列表：<br><img src="https://img-blog.csdnimg.cn/20190401142029667.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNDg2NjM5,size_16,color_FFFFFF,t_70" alt="Pass标签列表"></li><li>UsePass：可以使用该命令来服用其他Unity Shader中的Pass；</li><li>GrabPass：该Pass负责抓取屏幕并将结果存储在一张纹理中，以用于后续的Pass处理。<h3 id="Fallback"><a href="#Fallback" class="headerlink" title="Fallback"></a>Fallback</h3>紧跟在SubShader语句块后面，它用于告诉Unity，如果所有SubShader语句块在这块显卡上都不能运行，就是用这个最低级的Shader。<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">Fallback <span class="hljs-string">&quot;name&quot;</span><br><span class="hljs-regexp">//</span>或者<br>Fallback Off<br></code></pre></td></tr></table></figure>Fallback Off即如果所有SubShader都无法运行，那就不要管它了。</li></ul><h2 id="Unity-Shader形式"><a href="#Unity-Shader形式" class="headerlink" title="Unity Shader形式"></a>Unity Shader形式</h2><p>Unity Shader最重要的任务还是指定各种着色器所需的代码。这些着色器代码可以写在SubShader语义块中（表面着色器做法），也可以写在Pass语义块中（顶点&#x2F;片元着色器和固定函数着色器做法）。</p><h3 id="表面着色器（Surface-shader）"><a href="#表面着色器（Surface-shader）" class="headerlink" title="表面着色器（Surface shader）"></a>表面着色器（Surface shader）</h3><ul><li>由Unity自己创造的一种着色器，是对顶点&#x2F;片元着色器的进一步抽象，它需要的代码量很少，Unity在背后做了很多工作，但是渲染代价比较大。它存在的价值就是Unity帮我们处理了很多光照细节。</li><li>表面着色器被定义在CGPROGRAM和ENDCG中，并且不再pass语义块中，表面着色器并不在意你使用了多少个pass，unity会在背后进行处理。</li><li>CGPROGRAM和ENDCG中间的代码是使用CG&#x2F;HLSL编写的。<h3 id="顶点-x2F-片元着色器"><a href="#顶点-x2F-片元着色器" class="headerlink" title="顶点&#x2F;片元着色器"></a>顶点&#x2F;片元着色器</h3></li><li>在Unity中我们可以使用CG&#x2F;HLSL语言来编写顶点&#x2F;片元着色器，他们更加复杂，但是灵活度也更高。</li><li>顶点&#x2F;片元着色器是定义在pass语义块中的，虽然我们需要编写更多的代码，但我们可以控制渲染的细节。<h3 id="固定函数着色器"><a href="#固定函数着色器" class="headerlink" title="固定函数着色器"></a>固定函数着色器</h3></li><li>大部分设备都支持上面两种中的可编程管线，某些较旧的设备，不支持可编程管线着色器，我们需要使用固定函数着色器。</li><li>代码只相当于一些渲染设置，并且也是被定义在Pass语义块中，但它不是使用CG&#x2F;HLSL编写，而是完全使用ShaderLab编写。<h3 id="选择哪种渲染形式"><a href="#选择哪种渲染形式" class="headerlink" title="选择哪种渲染形式"></a>选择哪种渲染形式</h3></li><li>如果想和各种光源打交道，使用表面着色器，但要小心在移动平台上的效果。</li><li>如果光线较少，可以使用顶点&#x2F;片元着色器。</li><li>如果想实现很多自定义的渲染效果，那么选择顶点&#x2F;片元着色器。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>第二章-渲染流水线</title>
    <link href="/blog/2022/03/02/UnityShader/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%B8%B2%E6%9F%93%E6%B5%81%E6%B0%B4%E7%BA%BF/"/>
    <url>/blog/2022/03/02/UnityShader/%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%B8%B2%E6%9F%93%E6%B5%81%E6%B0%B4%E7%BA%BF/</url>
    
    <content type="html"><![CDATA[<h2 id="渲染流水线的起点是CPU"><a href="#渲染流水线的起点是CPU" class="headerlink" title="渲染流水线的起点是CPU"></a>渲染流水线的起点是CPU</h2><ul><li>应用程序阶段</li></ul><h3 id="把数据加载到显存中"><a href="#把数据加载到显存中" class="headerlink" title="把数据加载到显存中"></a>把数据加载到显存中</h3><ul><li>渲染所需数据从硬盘中加载到系统内存（RAM）中，又从系统内存中加载到显卡内存（VRAM）中。  </li><li>因为显卡对现存访问速度最快，并且大多数显卡对内存没有访问权限。  </li><li>数据加载到现存中后，系统内存中数据就可以删除，除非其中有数据会用作后续处理，例如网格数据用于碰撞检测则不进行删除。 因为从硬盘到内存的耗时较长，所以不会多次执行这个步骤。</li></ul><h3 id="设置渲染状态"><a href="#设置渲染状态" class="headerlink" title="设置渲染状态"></a>设置渲染状态</h3><ul><li>之后，开发者通过CPU设置渲染状态，从而指导GPU进行渲染。</li></ul><h3 id="调用Draw-Call"><a href="#调用Draw-Call" class="headerlink" title="调用Draw Call"></a>调用Draw Call</h3><ul><li>发起方是CPU，接收方是GPU。调用此方法只指向需要被渲染的图元列表。不再包涵任何材质信息，所有信息已经在前两步准备好了，GPU将信息整合计算并输出到屏幕上。</li></ul><h2 id="GPU流水线"><a href="#GPU流水线" class="headerlink" title="GPU流水线"></a>GPU流水线</h2><ul><li>几何概念阶段和光栅化概念阶段在GPU中执行</li></ul><h3 id="几何概念阶段"><a href="#几何概念阶段" class="headerlink" title="几何概念阶段"></a>几何概念阶段</h3><ul><li>顶点着色器 完全可编程</li><li>曲面细分着色器 可选着色器</li><li>几何着色器 可选着色器 可用于图元着色或者产生更多的图元</li><li>裁剪 可配置的 裁剪不再摄像头内的部分</li><li>屏幕映射 不可配置和编程 负责将每个图元的坐标转换到屏幕坐标上</li></ul><h3 id="光栅化概念阶段"><a href="#光栅化概念阶段" class="headerlink" title="光栅化概念阶段"></a>光栅化概念阶段</h3><ul><li>三角形设置阶段和三角形遍历阶段都是固定函数阶段。</li><li>片元着色器 完全可编程 实现逐片元着色</li><li>逐片元操作阶段 不可编程，具有很高配置性 修改颜色、深度缓冲、混合</li></ul><h3 id="详细解释"><a href="#详细解释" class="headerlink" title="详细解释"></a>详细解释</h3><h4 id="几何概念阶段："><a href="#几何概念阶段：" class="headerlink" title="几何概念阶段："></a>几何概念阶段：</h4><h4 id="顶点着色器"><a href="#顶点着色器" class="headerlink" title="顶点着色器"></a>顶点着色器</h4><ul><li>输入来自于CPU 处理单位为顶点 每次输入进来顶点都调用一次顶点着色器</li><li>其本身不可以创建或者销毁节点，也无法获得两个顶点之间的关系，这样的相互独立性，使GPU可以并行化处理每一个顶点。</li><li>主要工作：坐标变换和逐顶点光照。输出后续工作需要的数据</li><li>坐标变换：将顶点坐标从模型空间转换到齐次剪切空间。</li></ul><h4 id="裁剪"><a href="#裁剪" class="headerlink" title="裁剪"></a>裁剪</h4><ul><li>场景大小通常比摄像机可视范围大，将图元与摄像机的关系进行划分：完全在视野内、完全不在视野内、部分在视野内。</li><li>完全在视野内的传递到下一阶段。</li><li>完全不在视野内的不向下传递。</li><li>部分在视野内的，在分割处创建新的顶点，与视野内部分组成新图元传递到下一阶段，视野外部分不传递到下一阶段。</li></ul><h4 id="屏幕映射"><a href="#屏幕映射" class="headerlink" title="屏幕映射"></a>屏幕映射</h4><ul><li>将图元的x，y坐标转换为二维的屏幕坐标系中。</li><li>z坐标不作处理，z坐标与屏幕坐标系组成新的坐标系——窗口坐标系。</li><li>这些值传递到光栅化阶段。</li><li>ps：OpenGL中，屏幕左下角为最小坐标值，DirectX中，屏幕左上角为最小坐标值。</li></ul><h4 id="光栅化概念阶段："><a href="#光栅化概念阶段：" class="headerlink" title="光栅化概念阶段："></a>光栅化概念阶段：</h4><p>上一阶段输出信息：<br>顶点位置以及和它们相关的额外信息（例如：深度值即z坐标，法线方向，视角方向）<br>光栅化阶段重要目标：计算每个图元覆盖了哪些像素。</p><h4 id="三角形设置"><a href="#三角形设置" class="headerlink" title="三角形设置"></a>三角形设置</h4><ul><li>计算光栅化一个三角网格所需的信息。</li><li>计算每条边上的像素坐标，得出三角形边的表示方法。</li><li>输出为了下一个阶段做准备。</li></ul><h4 id="三角形遍历"><a href="#三角形遍历" class="headerlink" title="三角形遍历"></a>三角形遍历</h4><ul><li>检查每个像素是否被一个三角形网格覆盖，覆盖则生成一个片元。</li><li>输出一个片元序列。</li><li>ps：片元不等于像素，片元是一个包含了很多状态的集合，这些状态用于计算每个像素的最终颜色。</li></ul><h4 id="片元着色器（Directx中：像素着色器）"><a href="#片元着色器（Directx中：像素着色器）" class="headerlink" title="片元着色器（Directx中：像素着色器）"></a>片元着色器（Directx中：像素着色器）</h4><ul><li>另一个非常重要的可编程阶段。</li><li>完成很多重要的渲染操作，最重要的就是纹理采样。</li><li>输出一个或者多个颜色值</li><li>仅影响单个片元</li></ul><h4 id="逐片元操作（DirectX中：输出合并阶段）"><a href="#逐片元操作（DirectX中：输出合并阶段）" class="headerlink" title="逐片元操作（DirectX中：输出合并阶段）"></a>逐片元操作（DirectX中：输出合并阶段）</h4><ul><li>决定片元可见性</li><li>如果片元通过了所有测试，需要把这个片元的颜色值和已储存在颜色缓冲区的颜色合并。</li><li>高度可配置性指的是我们可以设置每一步的操作细节。</li><li>片元测试：<br>片元-&gt;模板测试-&gt;深度测试-&gt;混合-&gt;颜色缓冲区</li><li>模板测试：<br>读取该片元位置的模板值，然后将该值和读取到的参考值作比较，比较函数可以由开发者指定，如果没有通过测试，这个片元便会被舍弃，无论有没有通过测试，都可以根据结果以及之后深度测试的结果修改模板缓冲区。修改操作也由开发者指定。</li><li>深度测试：<br>将该片元的深度值与已经存在于深度缓冲区中的深度值作比较，比较函数也可以由开发者指定，通常为小于等于，以为我们总希望距离摄像机比较近的物体被渲染。如果这个片元没有通过测试，则被舍弃，并且没有更改深度缓冲区的权利。</li><li>合并：<br>在经过多次测试后，得到的值就要与上次绘制后颜色缓冲区的值合并，是覆盖之前的颜色还是其他处理就是合并操作需要处理的。</li><li>深度测试在片元着色器之前</li><li>光栅化时，没处理完一个片元就会对颜色缓冲区进行修改，即用户会看到不连贯的图像。所以GPU使用的双重缓冲，在后置缓冲中渲染场景，渲染结束后，与前值缓冲进行交换，避免了不连贯性。</li></ul>]]></content>
    
    
    <categories>
      
      <category>《UnityShader入门精要》</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
